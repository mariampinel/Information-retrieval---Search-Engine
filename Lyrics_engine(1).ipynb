{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b26bf20f-3cb5-4d63-b4bf-680baba29b09",
   "metadata": {},
   "source": [
    "# Lyrics search engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2215e2e0-896d-4d77-87e6-745919d8aa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "# !pip install rank_bm25\n",
    "# !pip install sentence_transformers\n",
    "import rank_bm25\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import json\n",
    "from rank_bm25 import BM25Okapi\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3379af4f-644b-40e0-a8d1-c2350f04319b",
   "metadata": {},
   "source": [
    "# Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c0f69c83-8a70-4066-9ae8-f03fc613407b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>tag</th>\n",
       "      <th>artist</th>\n",
       "      <th>year</th>\n",
       "      <th>views</th>\n",
       "      <th>features</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>id</th>\n",
       "      <th>preprocessed_lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Killa Cam</td>\n",
       "      <td>rap</td>\n",
       "      <td>Cam'ron</td>\n",
       "      <td>2004</td>\n",
       "      <td>173166</td>\n",
       "      <td>{\"Cam\\\\'ron\",\"Opera Steve\"}</td>\n",
       "      <td>[Chorus: Opera Steve &amp; Cam'ron]\\nKilla Cam, Ki...</td>\n",
       "      <td>1</td>\n",
       "      <td>[choru opera steve cam'ron] killa cam killa ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Can I Live</td>\n",
       "      <td>rap</td>\n",
       "      <td>JAY-Z</td>\n",
       "      <td>1996</td>\n",
       "      <td>468624</td>\n",
       "      <td>{}</td>\n",
       "      <td>[Produced by Irv Gotti]\\n\\n[Intro]\\nYeah, hah,...</td>\n",
       "      <td>3</td>\n",
       "      <td>[produc irv gotti] [intro] yeah hah yeah roc-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Down and Out</td>\n",
       "      <td>rap</td>\n",
       "      <td>Cam'ron</td>\n",
       "      <td>2004</td>\n",
       "      <td>144404</td>\n",
       "      <td>{\"Cam\\\\'ron\",\"Kanye West\",\"Syleena Johnson\"}</td>\n",
       "      <td>[Produced by Kanye West and Brian Miller]\\n\\n[...</td>\n",
       "      <td>5</td>\n",
       "      <td>[produc kany west brian miller] [intro cam'ron...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fly In</td>\n",
       "      <td>rap</td>\n",
       "      <td>Lil Wayne</td>\n",
       "      <td>2005</td>\n",
       "      <td>78271</td>\n",
       "      <td>{}</td>\n",
       "      <td>[Intro]\\nSo they ask me\\n\"Young boy\\nWhat you ...</td>\n",
       "      <td>6</td>\n",
       "      <td>[intro] ask me young boy you gon' second time ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lollipop Remix</td>\n",
       "      <td>rap</td>\n",
       "      <td>Lil Wayne</td>\n",
       "      <td>2008</td>\n",
       "      <td>580832</td>\n",
       "      <td>{\"Kanye West\",\"Static Major\"}</td>\n",
       "      <td>[Intro: Lil Wayne]\\nHaha\\nUh-huh\\nNo homo (You...</td>\n",
       "      <td>7</td>\n",
       "      <td>[intro lil wayne] haha uh-huh no homo young mu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            title  tag     artist  year   views  \\\n",
       "0       Killa Cam  rap    Cam'ron  2004  173166   \n",
       "1      Can I Live  rap      JAY-Z  1996  468624   \n",
       "2    Down and Out  rap    Cam'ron  2004  144404   \n",
       "3          Fly In  rap  Lil Wayne  2005   78271   \n",
       "4  Lollipop Remix  rap  Lil Wayne  2008  580832   \n",
       "\n",
       "                                       features  \\\n",
       "0                   {\"Cam\\\\'ron\",\"Opera Steve\"}   \n",
       "1                                            {}   \n",
       "2  {\"Cam\\\\'ron\",\"Kanye West\",\"Syleena Johnson\"}   \n",
       "3                                            {}   \n",
       "4                 {\"Kanye West\",\"Static Major\"}   \n",
       "\n",
       "                                              lyrics  id  \\\n",
       "0  [Chorus: Opera Steve & Cam'ron]\\nKilla Cam, Ki...   1   \n",
       "1  [Produced by Irv Gotti]\\n\\n[Intro]\\nYeah, hah,...   3   \n",
       "2  [Produced by Kanye West and Brian Miller]\\n\\n[...   5   \n",
       "3  [Intro]\\nSo they ask me\\n\"Young boy\\nWhat you ...   6   \n",
       "4  [Intro: Lil Wayne]\\nHaha\\nUh-huh\\nNo homo (You...   7   \n",
       "\n",
       "                                 preprocessed_lyrics  \n",
       "0  [choru opera steve cam'ron] killa cam killa ca...  \n",
       "1  [produc irv gotti] [intro] yeah hah yeah roc-a...  \n",
       "2  [produc kany west brian miller] [intro cam'ron...  \n",
       "3  [intro] ask me young boy you gon' second time ...  \n",
       "4  [intro lil wayne] haha uh-huh no homo young mu...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls= pd.read_csv('preprocessed_genius_lyrics.csv')\n",
    "ls.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "ls.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b242c497-8cd0-4016-b4aa-e3744532a314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          0\n",
       "1          1\n",
       "2          2\n",
       "3          3\n",
       "4          4\n",
       "        ... \n",
       "1144    1144\n",
       "1145    1145\n",
       "1146    1146\n",
       "1147    1147\n",
       "1148    1148\n",
       "Name: Unnamed: 0, Length: 1149, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0044976a-d87b-44a9-b5c4-bb5c259abe80",
   "metadata": {},
   "source": [
    "# Indexer\n",
    "\n",
    "The indexer creates an inverted index, mapping terms to their locations in documents for fast retrieval. \n",
    "- Needs preprocessed lyrics\n",
    "- Consists of two levels: a vocabulary of index terms (typically words) and lists that map each term to the documents where it appears.\n",
    "- Elasticsearch/Lucene builds inverted index\n",
    "- Metadata fields (genre, year, and song section) indexed separately.\n",
    "- Search engine incorporates a section-based filter: users to determine where their query terms appear in the lyrics (e.g., verse, chorus, bridge). - - These fields are structured using Elasticsearch mappings, allowing users to refine searches based on genre, release year, and specific song sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a91d832b-36b6-4fba-8a5b-5c7b9850ed95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apache Lucene or ElasticSearch\n",
    "# BM25 Inverted index\n",
    "# Query processor BM25. Prepare corpus fro BM25 (tokenized texts)\n",
    "\n",
    "def build_bm25_index(ls):\n",
    "    inverted_index = defaultdict(dict)\n",
    "    doc_lengths = {}\n",
    "    total_docs = len(ls)\n",
    "\n",
    "    for idx, row in ls.iterrows():\n",
    "        doc_id = row['id']\n",
    "        # Ensure tokens are separated properly\n",
    "        tokens = row['preprocessed_lyrics']\n",
    "        if isinstance(tokens, str):\n",
    "            tokens = tokens.split()\n",
    "\n",
    "        doc_lengths[doc_id] = len(tokens)\n",
    "\n",
    "        term_freqs = defaultdict(int)\n",
    "        for token in tokens:\n",
    "            term_freqs[token] += 1\n",
    "\n",
    "        for token, freq in term_freqs.items():\n",
    "            inverted_index[token][doc_id] = freq\n",
    "\n",
    "    return inverted_index, doc_lengths, total_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3fb8f90a-eac9-4bb1-928d-019133597ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT Embedder\n",
    "from sentence_transformers import SentenceTransformer\n",
    "def build_bert_index(ls, model_name='sentence-transformers/all-MiniLM-L6-v2'):\n",
    "    model = SentenceTransformer(model_name)\n",
    "    doc_texts = ls['preprocessed_lyrics'].astype(str).tolist()\n",
    "    doc_ids = ls['id'].tolist()\n",
    "\n",
    "    # Get embeddings\n",
    "    embeddings = model.encode(doc_texts, convert_to_numpy=True, show_progress_bar=True)\n",
    "\n",
    "    # Return doc IDs and embeddings\n",
    "    return dict(zip(doc_ids, embeddings))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bf91c2-02eb-4fdb-a7a2-fa215ec27dbc",
   "metadata": {},
   "source": [
    "# Query processor\n",
    "- Tokenizing, stemming, and normalizing the query using NLTK or spaCy\n",
    "- Input: Query\n",
    "1. Fuzzy matching incorporated using Levenshtein distance to approximate string matching\n",
    "    - Datamuse API: Related words and phrases through Datamuse API\n",
    "2. Filtering with Elasticsearch’s boolean queries (based on song metadata attributes, such as genre, release year, artist, and specific song sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c328cca3-7009-4ded-810a-fc83bc15dd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BM25 Scoring logic\n",
    "import re\n",
    "\n",
    "def preprocess_bm25_query(query):\n",
    "    # Lowercase, remove non-alphanumeric chars, split\n",
    "    query = query.lower()\n",
    "    tokens = re.findall(r'\\b\\w+\\b', query)  # Only words\n",
    "\n",
    "    return tokens  # Return list of tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9c315d35-eb0c-4a6b-b2ca-b581b07f32e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT Scoring logic\n",
    "def encode_bert_query(query, model):\n",
    "    # Encode the raw query string\n",
    "    embedding = model.encode(query, convert_to_numpy=True)\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b146c6d-e529-496e-ba8e-6208e8b80c43",
   "metadata": {},
   "source": [
    "# Baseline model: BM25 + BERT\n",
    "- Generates relevance scores for lyrics based on user's query\n",
    "\n",
    "- Ranking layer 1: BM25+BERT\n",
    "- Ranking layer 2: Datamuse API for phonetic alignment of lyrics with query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f618f15-c16d-4fb9-ac9d-6e015ac91dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ranking of lyrics with BM25\n",
    "\n",
    "# Load preprocessed lyrics\n",
    "tokenized_corpus = [str(doc).split() for doc in ls['preprocessed_lyrics']]\n",
    "bm25 = BM25Okapi(tokenized_corpus)\n",
    "\n",
    "def bm25_search(query, top_k=5):\n",
    "    tokens = preprocess_bm25_query(query)\n",
    "    scores = bm25.get_scores(tokens)\n",
    "    top_indices = np.argsort(scores)[::-1][:top_k]\n",
    "    return ls.iloc[top_indices][['title', 'artist', 'lyrics']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2d6d1409-13a0-44a5-9188-2bc46c4c7cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed query for BERT model to compare with document embeddings\n",
    "\n",
    "def bert_search(query, doc_embeddings, model, ls, top_k=5):\n",
    "    query_vec = encode_bert_query(query, model)\n",
    "\n",
    "    # Compute cosine similarity to each document\n",
    "    doc_ids = list(doc_embeddings.keys())\n",
    "    doc_vecs = np.array([doc_embeddings[doc_id] for doc_id in doc_ids])\n",
    "    \n",
    "    similarities = cosine_similarity([query_vec], doc_vecs)[0]\n",
    "    top_indices = np.argsort(similarities)[::-1][:top_k]\n",
    "\n",
    "    top_doc_ids = [doc_ids[i] for i in top_indices]\n",
    "    return ls[ls['id'].isin(top_doc_ids)][['title', 'artist', 'lyrics']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ece673a-e3c9-46df-aa6f-eb8f61aa727a",
   "metadata": {},
   "source": [
    "# Enter query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "47ca914d-bebd-45ad-8dfa-53d4ae06620b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "857a725ddcc84b29875d8e531bb880f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7342af528de7410388822dc8cde679e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ffab322061e4a9284909679e15682e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b45319c8a4c44706a3c474db1b0a1dee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "824fde5430d94f30b018214ed7791630",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03d1635fb8c14890b991ced3f280436c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43c08337f6584a83bd825377b1795422",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f7dd67c183541f5b5f802ce5c46c36f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a204df51e45456bb44e4c818c10f9ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2e953798335457886e16c4c07118a6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e554e68e2444ca48ca87a1180dd7803",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19211c1cac54429980d6545bbeb51a27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m bm25_model \u001b[38;5;241m=\u001b[39m BM25Okapi(tokenized_corpus)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Step 2: Build BERT index\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m bert_index, bert_model \u001b[38;5;241m=\u001b[39m build_bert_index(ls)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Step 3: Example Query\u001b[39;00m\n\u001b[1;32m      9\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeeling heartbroken and lost love\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "# Step 1: Build BM25 model using preprocessed_lyrics\n",
    "tokenized_corpus = [str(doc).split() for doc in ls['preprocessed_lyrics']]\n",
    "bm25_model = BM25Okapi(tokenized_corpus)\n",
    "\n",
    "# Step 2: Build BERT index\n",
    "bert_index, bert_model = build_bert_index(ls)\n",
    "\n",
    "# Step 3: Example Query\n",
    "query = \"feeling heartbroken and lost love\"\n",
    "\n",
    "print(\"BM25 Results:\\n\")\n",
    "print(bm25_search(query, ls, bm25_model))\n",
    "\n",
    "print(\"\\nBERT Results:\\n\")\n",
    "print(bert_search(query, ls, bert_index, bert_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d80f4507-c130-4344-ae56-73e09f9e79a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hybrid search\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "def hybrid_search(query, ls, bm25_model, bert_model, bert_index, top_k_bm25=20, top_k_final=5, weight=0.5):\n",
    "    \"\"\"\n",
    "    Performs hybrid search using BM25 followed by BERT re-ranking.\n",
    "\n",
    "    Parameters:\n",
    "    - query (str): user query string\n",
    "    - ls (DataFrame): lyrics DataFrame\n",
    "    - bm25_model (BM25Okapi): pre-built BM25 model\n",
    "    - bert_model (SentenceTransformer): preloaded BERT model\n",
    "    - bert_index (dict): doc_id -> embedding\n",
    "    - top_k_bm25 (int): how many candidates to retrieve from BM25\n",
    "    - top_k_final (int): how many final results to return\n",
    "    - weight (float): weight of BERT in final score (0–1)\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame of top results with combined ranking\n",
    "    \"\"\"\n",
    "    # Step 1: BM25 Search\n",
    "    bm25_tokens = query.lower().split()\n",
    "    bm25_scores = bm25_model.get_scores(bm25_tokens)\n",
    "    bm25_top_indices = np.argsort(bm25_scores)[::-1][:top_k_bm25]\n",
    "    bm25_top_ids = ls.iloc[bm25_top_indices]['id'].tolist()\n",
    "    \n",
    "    # Step 2: BERT query embedding\n",
    "    query_embedding = bert_model.encode(query, convert_to_numpy=True)\n",
    "\n",
    "    # Step 3: BERT scores for BM25 top candidates\n",
    "    bert_scores = []\n",
    "    bm25_selected_scores = []\n",
    "    for doc_id in bm25_top_ids:\n",
    "        doc_embedding = bert_index[doc_id]\n",
    "        sim = cosine_similarity([query_embedding], [doc_embedding])[0][0]\n",
    "        bert_scores.append(sim)\n",
    "        bm25_selected_scores.append(bm25_scores[ls[ls['id'] == doc_id].index[0]])\n",
    "\n",
    "    # Step 4: Normalize scores\n",
    "    bert_scores = np.array(bert_scores)\n",
    "    bm25_selected_scores = np.array(bm25_selected_scores)\n",
    "\n",
    "    bert_norm = (bert_scores - bert_scores.min()) / (bert_scores.max() - bert_scores.min() + 1e-8)\n",
    "    bm25_norm = (bm25_selected_scores - bm25_selected_scores.min()) / (bm25_selected_scores.max() - bm25_selected_scores.min() + 1e-8)\n",
    "\n",
    "    # Step 5: Combine and sort\n",
    "    combined_scores = weight * bert_norm + (1 - weight) * bm25_norm\n",
    "    sorted_indices = np.argsort(combined_scores)[::-1][:top_k_final]\n",
    "    final_ids = [bm25_top_ids[i] for i in sorted_indices]\n",
    "\n",
    "    return ls[ls['id'].isin(final_ids)][['id', 'title', 'artist', 'lyrics']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf133a2-0567-4ff1-9561-7e393cb5f4a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf130fd5912445a3a10f2ecceedf6ca5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Implement hybrid search\n",
    "bm25_model = BM25Okapi([str(doc).split() for doc in ls['preprocessed_lyrics']])\n",
    "bert_index, bert_model = build_bert_index(ls)\n",
    "\n",
    "query = \"lonely heartbreak in the rain\"\n",
    "results = hybrid_search(query, ls, bm25_model, bert_model, bert_index, weight=0.6)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9294abc-0e11-473d-aa16-c721dbfb5390",
   "metadata": {},
   "source": [
    "# Analyze results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45acd85b-5e79-4e61-8ada-c9bf6a1b7494",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analyze results\n",
    "def analyze_results(results_df):\n",
    "    comparison_counts = results_df['comparison'].value_counts()\n",
    "\n",
    "    total_results = len(results_df)\n",
    "\n",
    "    analysis_df = pd.DataFrame({\n",
    "        \"Count\": comparison_counts,\n",
    "        \"Percentage\": (comparison_counts / total_results) * 100\n",
    "    })\n",
    "\n",
    "    for status in ['Improved', 'Unchanged', 'Worsened']:\n",
    "        if status not in analysis_df.index:\n",
    "            analysis_df.loc[status] = [0, 0.0]  # Add missing status with 0 count and 0% percentage\n",
    "\n",
    "    analysis_df = analysis_df.loc[['Improved', 'Unchanged', 'Worsened']]\n",
    "\n",
    "    return analysis_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e2b10a-5c2f-49a3-9de3-509974fa2256",
   "metadata": {},
   "source": [
    "# Augmented model: BM25 + Datamuse API + BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651c9fbc-121e-4115-af60-5c3bd6e3c9fc",
   "metadata": {},
   "source": [
    "# References\n",
    "https://medium.com/@bormotovk/hybrid-retrieval-combining-bert-and-bm25-for-enhanced-performance-4f6f80881c13\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
