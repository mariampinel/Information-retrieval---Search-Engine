{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b26bf20f-3cb5-4d63-b4bf-680baba29b09",
   "metadata": {},
   "source": [
    "# Lyrics search engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2215e2e0-896d-4d77-87e6-745919d8aa59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rank_bm25\n",
      "  Using cached rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from rank_bm25) (2.0.2)\n",
      "Using cached rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
      "Installing collected packages: rank_bm25\n",
      "Successfully installed rank_bm25-0.2.2\n",
      "Collecting sentence_transformers\n",
      "  Using cached sentence_transformers-4.0.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence_transformers)\n",
      "  Using cached transformers-4.51.2-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from sentence_transformers) (4.66.5)\n",
      "Collecting torch>=1.11.0 (from sentence_transformers)\n",
      "  Using cached torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.11/site-packages (from sentence_transformers) (1.5.1)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.11/site-packages (from sentence_transformers) (1.14.1)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence_transformers)\n",
      "  Using cached huggingface_hub-0.30.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.11/site-packages (from sentence_transformers) (10.4.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /opt/conda/lib/python3.11/site-packages (from sentence_transformers) (4.12.2)\n",
      "Collecting filelock (from huggingface-hub>=0.20.0->sentence_transformers)\n",
      "  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2.32.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence_transformers)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence_transformers)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence_transformers)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence_transformers)\n",
      "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence_transformers)\n",
      "  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence_transformers)\n",
      "  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence_transformers)\n",
      "  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence_transformers)\n",
      "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence_transformers)\n",
      "  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.6.2 (from torch>=1.11.0->sentence_transformers)\n",
      "  Using cached nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting nvidia-nccl-cu12==2.21.5 (from torch>=1.11.0->sentence_transformers)\n",
      "  Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.4.127 (from torch>=1.11.0->sentence_transformers)\n",
      "  Using cached nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence_transformers)\n",
      "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.2.0 (from torch>=1.11.0->sentence_transformers)\n",
      "  Using cached triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Collecting sympy==1.13.1 (from torch>=1.11.0->sentence_transformers)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2.0.2)\n",
      "Collecting regex!=2019.12.17 (from transformers<5.0.0,>=4.41.0->sentence_transformers)\n",
      "  Using cached regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers<5.0.0,>=4.41.0->sentence_transformers)\n",
      "  Using cached tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers<5.0.0,>=4.41.0->sentence_transformers)\n",
      "  Using cached safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2024.8.30)\n",
      "Using cached sentence_transformers-4.0.2-py3-none-any.whl (340 kB)\n",
      "Using cached huggingface_hub-0.30.2-py3-none-any.whl (481 kB)\n",
      "Using cached torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl (766.7 MB)\n",
      "Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "Using cached nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
      "Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "Using cached nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Using cached triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.2 MB)\n",
      "Using cached transformers-4.51.2-py3-none-any.whl (10.4 MB)\n",
      "Using cached regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (792 kB)\n",
      "Using cached safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "Using cached tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "Using cached filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Installing collected packages: triton, nvidia-cusparselt-cu12, sympy, safetensors, regex, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, filelock, nvidia-cusparse-cu12, nvidia-cudnn-cu12, huggingface-hub, tokenizers, nvidia-cusolver-cu12, transformers, torch, sentence_transformers\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.13.2\n",
      "    Uninstalling sympy-1.13.2:\n",
      "      Successfully uninstalled sympy-1.13.2\n",
      "Successfully installed filelock-3.18.0 huggingface-hub-0.30.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 regex-2024.11.6 safetensors-0.5.3 sentence_transformers-4.0.2 sympy-1.13.1 tokenizers-0.21.1 torch-2.6.0 transformers-4.51.2 triton-3.2.0\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "!pip install rank_bm25\n",
    "!pip install sentence_transformers\n",
    "import rank_bm25\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import json\n",
    "from rank_bm25 import BM25Okapi\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from rank_bm25 import BM25Okapi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3379af4f-644b-40e0-a8d1-c2350f04319b",
   "metadata": {},
   "source": [
    "# Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0f69c83-8a70-4066-9ae8-f03fc613407b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>tag</th>\n",
       "      <th>artist</th>\n",
       "      <th>year</th>\n",
       "      <th>views</th>\n",
       "      <th>features</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>id</th>\n",
       "      <th>preprocessed_lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Killa Cam</td>\n",
       "      <td>rap</td>\n",
       "      <td>Cam'ron</td>\n",
       "      <td>2004</td>\n",
       "      <td>173166</td>\n",
       "      <td>{\"Cam\\\\'ron\",\"Opera Steve\"}</td>\n",
       "      <td>[Chorus: Opera Steve &amp; Cam'ron]\\nKilla Cam, Ki...</td>\n",
       "      <td>1</td>\n",
       "      <td>[choru opera steve cam'ron] killa cam killa ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Can I Live</td>\n",
       "      <td>rap</td>\n",
       "      <td>JAY-Z</td>\n",
       "      <td>1996</td>\n",
       "      <td>468624</td>\n",
       "      <td>{}</td>\n",
       "      <td>[Produced by Irv Gotti]\\n\\n[Intro]\\nYeah, hah,...</td>\n",
       "      <td>3</td>\n",
       "      <td>[produc irv gotti] [intro] yeah hah yeah roc-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Down and Out</td>\n",
       "      <td>rap</td>\n",
       "      <td>Cam'ron</td>\n",
       "      <td>2004</td>\n",
       "      <td>144404</td>\n",
       "      <td>{\"Cam\\\\'ron\",\"Kanye West\",\"Syleena Johnson\"}</td>\n",
       "      <td>[Produced by Kanye West and Brian Miller]\\n\\n[...</td>\n",
       "      <td>5</td>\n",
       "      <td>[produc kany west brian miller] [intro cam'ron...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fly In</td>\n",
       "      <td>rap</td>\n",
       "      <td>Lil Wayne</td>\n",
       "      <td>2005</td>\n",
       "      <td>78271</td>\n",
       "      <td>{}</td>\n",
       "      <td>[Intro]\\nSo they ask me\\n\"Young boy\\nWhat you ...</td>\n",
       "      <td>6</td>\n",
       "      <td>[intro] ask me young boy you gon' second time ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lollipop Remix</td>\n",
       "      <td>rap</td>\n",
       "      <td>Lil Wayne</td>\n",
       "      <td>2008</td>\n",
       "      <td>580832</td>\n",
       "      <td>{\"Kanye West\",\"Static Major\"}</td>\n",
       "      <td>[Intro: Lil Wayne]\\nHaha\\nUh-huh\\nNo homo (You...</td>\n",
       "      <td>7</td>\n",
       "      <td>[intro lil wayne] haha uh-huh no homo young mu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            title  tag     artist  year   views  \\\n",
       "0       Killa Cam  rap    Cam'ron  2004  173166   \n",
       "1      Can I Live  rap      JAY-Z  1996  468624   \n",
       "2    Down and Out  rap    Cam'ron  2004  144404   \n",
       "3          Fly In  rap  Lil Wayne  2005   78271   \n",
       "4  Lollipop Remix  rap  Lil Wayne  2008  580832   \n",
       "\n",
       "                                       features  \\\n",
       "0                   {\"Cam\\\\'ron\",\"Opera Steve\"}   \n",
       "1                                            {}   \n",
       "2  {\"Cam\\\\'ron\",\"Kanye West\",\"Syleena Johnson\"}   \n",
       "3                                            {}   \n",
       "4                 {\"Kanye West\",\"Static Major\"}   \n",
       "\n",
       "                                              lyrics  id  \\\n",
       "0  [Chorus: Opera Steve & Cam'ron]\\nKilla Cam, Ki...   1   \n",
       "1  [Produced by Irv Gotti]\\n\\n[Intro]\\nYeah, hah,...   3   \n",
       "2  [Produced by Kanye West and Brian Miller]\\n\\n[...   5   \n",
       "3  [Intro]\\nSo they ask me\\n\"Young boy\\nWhat you ...   6   \n",
       "4  [Intro: Lil Wayne]\\nHaha\\nUh-huh\\nNo homo (You...   7   \n",
       "\n",
       "                                 preprocessed_lyrics  \n",
       "0  [choru opera steve cam'ron] killa cam killa ca...  \n",
       "1  [produc irv gotti] [intro] yeah hah yeah roc-a...  \n",
       "2  [produc kany west brian miller] [intro cam'ron...  \n",
       "3  [intro] ask me young boy you gon' second time ...  \n",
       "4  [intro lil wayne] haha uh-huh no homo young mu...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls= pd.read_csv('preprocessed_genius_lyrics.csv')\n",
    "ls.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "ls.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b242c497-8cd0-4016-b4aa-e3744532a314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [Chorus: Opera Steve & Cam'ron]\\nKilla Cam, Ki...\n",
       "1       [Produced by Irv Gotti]\\n\\n[Intro]\\nYeah, hah,...\n",
       "2       [Produced by Kanye West and Brian Miller]\\n\\n[...\n",
       "3       [Intro]\\nSo they ask me\\n\"Young boy\\nWhat you ...\n",
       "4       [Intro: Lil Wayne]\\nHaha\\nUh-huh\\nNo homo (You...\n",
       "                              ...                        \n",
       "1144    [Hook]\\nAnother night, slips away\\nIn other wo...\n",
       "1145    [Intro: Michael Jackson and 60 Minutes' Ed Bra...\n",
       "1146    [Chorus: Kid Cudi & John Legend]\\nI got the wo...\n",
       "1147    [Chorus 1: Bruno Mars & B.o.B]\\nBeautiful girl...\n",
       "1148    [Intro]\\nK-K-K-K-K-K-Mac\\n\\n[Verse 1: Chris Br...\n",
       "Name: lyrics, Length: 1149, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls['lyrics']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0044976a-d87b-44a9-b5c4-bb5c259abe80",
   "metadata": {},
   "source": [
    "# Indexer\n",
    "\n",
    "The indexer creates an inverted index, mapping terms to their locations in documents for fast retrieval. \n",
    "- Needs preprocessed lyrics\n",
    "- Consists of two levels: a vocabulary of index terms (typically words) and lists that map each term to the documents where it appears.\n",
    "- Elasticsearch/Lucene builds inverted index\n",
    "- Metadata fields (genre, year, and song section) indexed separately.\n",
    "- Search engine incorporates a section-based filter: users to determine where their query terms appear in the lyrics (e.g., verse, chorus, bridge). - - These fields are structured using Elasticsearch mappings, allowing users to refine searches based on genre, release year, and specific song sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a91d832b-36b6-4fba-8a5b-5c7b9850ed95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apache Lucene or ElasticSearch\n",
    "# BM25 Inverted index\n",
    "# Query processor BM25. Prepare corpus fro BM25 (tokenized texts)\n",
    "\n",
    "def build_bm25_index(ls):\n",
    "    inverted_index = defaultdict(dict)\n",
    "    doc_lengths = {}\n",
    "    total_docs = len(ls)\n",
    "\n",
    "    for idx, row in ls.iterrows():\n",
    "        doc_id = row['id']\n",
    "        # Ensure tokens are separated properly\n",
    "        tokens = row['preprocessed_lyrics']\n",
    "        if isinstance(tokens, str):\n",
    "            tokens = tokens.split()\n",
    "\n",
    "        doc_lengths[doc_id] = len(tokens)\n",
    "\n",
    "        term_freqs = defaultdict(int)\n",
    "        for token in tokens:\n",
    "            term_freqs[token] += 1\n",
    "\n",
    "        for token, freq in term_freqs.items():\n",
    "            inverted_index[token][doc_id] = freq\n",
    "\n",
    "    return inverted_index, doc_lengths, total_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3fb8f90a-eac9-4bb1-928d-019133597ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT Embedder\n",
    "bert_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "def build_bert_index(ls, model_name=\"sentence-transformers/all-MiniLM-L6-v2\"):\n",
    "    model = SentenceTransformer(model_name)\n",
    "    lyrics_texts = ls['preprocessed_lyrics'].astype(str).tolist()\n",
    "    embeddings = model.encode(lyrics_texts, convert_to_numpy=True)\n",
    "    doc_ids = ls[\"id\"].tolist()\n",
    "    doc_embeddings = dict(zip(doc_ids, embeddings))\n",
    "    return doc_embeddings, model  #  returns both index and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f3223994-6835-4644-8d36-50d44fe8d0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_embeddings = np.load('bert_embeddings.npy',allow_pickle=False)\n",
    "\n",
    "# Get document IDs from your DataFrame\n",
    "doc_ids = ls[\"id\"].tolist()\n",
    "\n",
    "# Build a dictionary: {doc_id: embedding}\n",
    "bert_embeddings = dict(zip(doc_ids, bert_embeddings))\n",
    "# bert_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bf91c2-02eb-4fdb-a7a2-fa215ec27dbc",
   "metadata": {},
   "source": [
    "# Query processor\n",
    "- Tokenizing, stemming, and normalizing the query using NLTK or spaCy\n",
    "- Input: Query\n",
    "1. Fuzzy matching incorporated using Levenshtein distance to approximate string matching\n",
    "    - Datamuse API: Related words and phrases through Datamuse API\n",
    "2. Filtering with Elasticsearchâ€™s boolean queries (based on song metadata attributes, such as genre, release year, artist, and specific song sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c328cca3-7009-4ded-810a-fc83bc15dd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BM25 Scoring logic\n",
    "import re\n",
    "\n",
    "def preprocess_bm25_query(query):\n",
    "    # Lowercase, remove non-alphanumeric chars, split\n",
    "    query = query.lower()\n",
    "    tokens = re.findall(r'\\b\\w+\\b', query)  # Only words\n",
    "\n",
    "    return tokens  # Return list of tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9c315d35-eb0c-4a6b-b2ca-b581b07f32e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT Scoring logic\n",
    "def encode_bert_query(query, model):\n",
    "    # Encode the raw query string\n",
    "    embedding = model.encode(query)\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b146c6d-e529-496e-ba8e-6208e8b80c43",
   "metadata": {},
   "source": [
    "# Baseline model: BM25 + BERT\n",
    "- Generates relevance scores for lyrics based on user's query\n",
    "\n",
    "- Ranking layer 1: BM25+BERT\n",
    "- Ranking layer 2: Datamuse API for phonetic alignment of lyrics with query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f618f15-c16d-4fb9-ac9d-6e015ac91dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ranking of lyrics with BM25\n",
    "\n",
    "# Load preprocessed lyrics\n",
    "tokenized_corpus = [str(doc).split() for doc in ls['preprocessed_lyrics']]\n",
    "bm25 = BM25Okapi(tokenized_corpus)\n",
    "\n",
    "def bm25_search(query, top_k=5):\n",
    "    tokens = preprocess_bm25_query(query)\n",
    "    scores = bm25.get_scores(tokens)\n",
    "    top_indices = np.argsort(scores)[::-1][:top_k]\n",
    "    return ls.iloc[top_indices][['title', 'artist', 'lyrics']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2d6d1409-13a0-44a5-9188-2bc46c4c7cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed query for BERT model to compare with document embeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "def bert_search(query, doc_embeddings, model, ls, top_k=5):\n",
    "    query_vec = encode_bert_query(query, model)\n",
    "\n",
    "    # Compute cosine similarity to each document\n",
    "    doc_ids = list(doc_embeddings.keys())\n",
    "    doc_vecs = np.array([doc_embeddings[doc_id] for doc_id in doc_ids])\n",
    "    \n",
    "    similarities = cosine_similarity([query_vec], doc_vecs)[0]\n",
    "    top_indices = np.argsort(similarities)[::-1][:top_k]\n",
    "\n",
    "    top_doc_ids = [doc_ids[i] for i in top_indices]\n",
    "    return ls[ls['id'].isin(top_doc_ids)][['title', 'artist', 'lyrics']]\n",
    "\n",
    "# def build_bert_index(ls, model_name=\"sentence-transformers/all-MiniLM-L6-v2\"):\n",
    "#     model = SentenceTransformer(model_name)\n",
    "#     lyrics_texts = ls['preprocessed_lyrics'].astype(str).tolist()\n",
    "#     embeddings = model.encode(lyrics_texts, convert_to_numpy=True)\n",
    "#     doc_ids = ls[\"id\"].tolist()\n",
    "#     doc_embeddings = dict(zip(doc_ids, embeddings))\n",
    "#     return doc_embeddings, model  #  returns both index and model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ece673a-e3c9-46df-aa6f-eb8f61aa727a",
   "metadata": {},
   "source": [
    "# Enter query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "47ca914d-bebd-45ad-8dfa-53d4ae06620b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BM25 Results:\n",
      "\n",
      "                  title     artist  \\\n",
      "61             Go Crazy      Jeezy   \n",
      "134  This Is the Carter  Lil Wayne   \n",
      "847            Mr. 17.5      Jeezy   \n",
      "174         I Told Yall  Lil Wayne   \n",
      "320     Look Like Jesus      Lil B   \n",
      "\n",
      "                                                lyrics  \n",
      "61   [Produced by Don Cannon]\\n\\n[Verse 1: Young Je...  \n",
      "134  [Intro: Lil Wayne & Mannie Fresh]\\nOkay, um, f...  \n",
      "847  [Verse 1: Young Jeezy]\\nNew shoes on the Range...  \n",
      "174  [Intro: DJ K-Swift & Lil Wayne]\\nTold y'all, I...  \n",
      "320  [Intro]\\nNiggas hatin on me bro, but I don't g...  \n",
      "\n",
      "BERT Results:\n",
      "\n",
      "                          title     artist  \\\n",
      "3                        Fly In  Lil Wayne   \n",
      "12   What Happened to That Boy?    Birdman   \n",
      "413                My President      Jeezy   \n",
      "495                   Hype Boys       Sway   \n",
      "590               Young Forever      JAY-Z   \n",
      "\n",
      "                                                lyrics  \n",
      "3    [Intro]\\nSo they ask me\\n\"Young boy\\nWhat you ...  \n",
      "12   [Intro: Birdman]\\nAyy-ayy, ayy, ayy\\nYeah\\nTot...  \n",
      "413  [Intro: Young Jeezy]\\nYeah, be the realest shi...  \n",
      "495  [Verse 1]\\nHype boys, hype boys, everyone's a ...  \n",
      "590  [Intro: Mr. Hudson]\\nLet's dance in style, let...  \n"
     ]
    }
   ],
   "source": [
    "# Step 1: Build BM25 model using preprocessed_lyrics\n",
    "tokenized_corpus = [str(doc).split() for doc in ls['preprocessed_lyrics']]\n",
    "bm25_model = BM25Okapi(tokenized_corpus)\n",
    "\n",
    "# # Step 2: Build BERT index\n",
    "# bert_index, bert_model = build_bert_index(ls, model_name)\n",
    "\n",
    "# Step 3: Example Query\n",
    "query = \"Young boy\"\n",
    "\n",
    "print(\"BM25 Results:\\n\")\n",
    "print(bm25_search(query, 5))\n",
    "\n",
    "print(\"\\nBERT Results:\\n\")\n",
    "print(bert_search(query, bert_embeddings, bert_model, ls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d80f4507-c130-4344-ae56-73e09f9e79a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hybrid search\n",
    "bert_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "def hybrid_search(query, ls, bm25_model, bert_model, bert_embeddings, top_k_bm25=20, top_k_final=5, weight=0.5):\n",
    "\n",
    "    # Step 1: BM25 Search\n",
    "    bm25_tokens = query.lower().split()\n",
    "    bm25_scores = bm25_model.get_scores(bm25_tokens)\n",
    "    bm25_top_indices = np.argsort(bm25_scores)[::-1][:top_k_bm25]\n",
    "    bm25_top_ids = ls.iloc[bm25_top_indices]['id'].tolist()\n",
    "    \n",
    "    # Step 2: BERT query embedding\n",
    "    query_embedding = bert_model.encode(query, convert_to_numpy=True)\n",
    "\n",
    "    # Step 3: BERT scores for BM25 top candidates\n",
    "    bert_scores = []\n",
    "    bm25_selected_scores = []\n",
    "    for doc_id in bm25_top_ids:\n",
    "        doc_embedding = bert_embeddings[doc_id]\n",
    "        sim = cosine_similarity([query_embedding], [doc_embedding])[0][0]\n",
    "        bert_scores.append(sim)\n",
    "        bm25_selected_scores.append(bm25_scores[ls[ls['id'] == doc_id].index[0]])\n",
    "\n",
    "    # Step 4: Normalize scores\n",
    "    bert_scores = np.array(bert_scores)\n",
    "    bm25_selected_scores = np.array(bm25_selected_scores)\n",
    "\n",
    "    bert_norm = (bert_scores - bert_scores.min()) / (bert_scores.max() - bert_scores.min() + 1e-8)\n",
    "    bm25_norm = (bm25_selected_scores - bm25_selected_scores.min()) / (bm25_selected_scores.max() - bm25_selected_scores.min() + 1e-8)\n",
    "\n",
    "    # Step 5: Combine and sort\n",
    "    combined_scores = weight * bert_norm + (1 - weight) * bm25_norm\n",
    "    sorted_indices = np.argsort(combined_scores)[::-1][:top_k_final]\n",
    "    final_ids = [bm25_top_ids[i] for i in sorted_indices]\n",
    "\n",
    "    return ls[ls['id'].isin(final_ids)][['id', 'title', 'artist', 'lyrics']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cdf133a2-0567-4ff1-9561-7e393cb5f4a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id         title     artist  \\\n",
      "70      83  Mrs. Officer  Lil Wayne   \n",
      "347    410       My Time   Fabolous   \n",
      "711    820         Trill     Clipse   \n",
      "915   1077     Music Box     Eminem   \n",
      "1135  1395     Blasphemy       2Pac   \n",
      "\n",
      "                                                 lyrics  \n",
      "70    [Intro: Bobby Valentino & (Lil Wayne)]\\nAyy\\nA...  \n",
      "347   [Hook: Jeremih]\\nGo hard today\\nCan't worry 'b...  \n",
      "711   [Chorus: Pharrell]\\nUh, I got jewels (Uh), plu...  \n",
      "915   [Intro]\\nYeah\\nYeah, girl\\nCan you hear that? ...  \n",
      "1135  [Intro: This Week In Bible Prophecy]\\nGod has ...  \n"
     ]
    }
   ],
   "source": [
    "# Implement hybrid search\n",
    "bm25_model = BM25Okapi([str(doc).split() for doc in ls['preprocessed_lyrics']])\n",
    "query = \"i hear jerusalem bells\"\n",
    "results = hybrid_search(query, ls, bm25_model, bert_model, bert_embeddings, 20, 5, weight=0.1)\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9294abc-0e11-473d-aa16-c721dbfb5390",
   "metadata": {},
   "source": [
    "# Analyze results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45acd85b-5e79-4e61-8ada-c9bf6a1b7494",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analyze results\n",
    "def analyze_results(results_df):\n",
    "    comparison_counts = results_df['comparison'].value_counts()\n",
    "\n",
    "    total_results = len(results_df)\n",
    "\n",
    "    analysis_df = pd.DataFrame({\n",
    "        \"Count\": comparison_counts,\n",
    "        \"Percentage\": (comparison_counts / total_results) * 100\n",
    "    })\n",
    "\n",
    "    for status in ['Improved', 'Unchanged', 'Worsened']:\n",
    "        if status not in analysis_df.index:\n",
    "            analysis_df.loc[status] = [0, 0.0]  # Add missing status with 0 count and 0% percentage\n",
    "\n",
    "    analysis_df = analysis_df.loc[['Improved', 'Unchanged', 'Worsened']]\n",
    "\n",
    "    return analysis_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e2b10a-5c2f-49a3-9de3-509974fa2256",
   "metadata": {},
   "source": [
    "# Augmented model: BM25 + Datamuse API + BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651c9fbc-121e-4115-af60-5c3bd6e3c9fc",
   "metadata": {},
   "source": [
    "# References\n",
    "https://medium.com/@bormotovk/hybrid-retrieval-combining-bert-and-bm25-for-enhanced-performance-4f6f80881c13\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
