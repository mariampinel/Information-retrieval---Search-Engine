{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b26bf20f-3cb5-4d63-b4bf-680baba29b09",
   "metadata": {},
   "source": [
    "# Lyrics search engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2215e2e0-896d-4d77-87e6-745919d8aa59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rank_bm25 in /opt/conda/lib/python3.11/site-packages (0.2.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from rank_bm25) (2.0.2)\n",
      "Requirement already satisfied: sentence_transformers in /opt/conda/lib/python3.11/site-packages (4.0.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /opt/conda/lib/python3.11/site-packages (from sentence_transformers) (4.51.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from sentence_transformers) (4.66.5)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.11/site-packages (from sentence_transformers) (2.6.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.11/site-packages (from sentence_transformers) (1.5.1)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.11/site-packages (from sentence_transformers) (1.14.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /opt/conda/lib/python3.11/site-packages (from sentence_transformers) (0.30.2)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.11/site-packages (from sentence_transformers) (10.4.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /opt/conda/lib/python3.11/site-packages (from sentence_transformers) (4.12.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2.32.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /opt/conda/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /opt/conda/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.5.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2024.8.30)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.11/site-packages (3.9.1)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.11/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.11/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.11/site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from nltk) (4.66.5)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "!pip install rank_bm25\n",
    "!pip install sentence_transformers\n",
    "!pip install nltk\n",
    "!pip install requests\n",
    "\n",
    "import rank_bm25\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import json\n",
    "from rank_bm25 import BM25Okapi\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from rank_bm25 import BM25Okapi\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3379af4f-644b-40e0-a8d1-c2350f04319b",
   "metadata": {},
   "source": [
    "# Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c0f69c83-8a70-4066-9ae8-f03fc613407b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls= pd.read_csv('preprocessed_genius_lyrics.csv')\n",
    "ls.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "ls=ls.rename(columns={'tag':'genre'})\n",
    "# ls['preprocessed_lyrics'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b242c497-8cd0-4016-b4aa-e3744532a314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [Chorus: Opera Steve & Cam'ron]\\nKilla Cam, Ki...\n",
       "1       [Produced by Irv Gotti]\\n\\n[Intro]\\nYeah, hah,...\n",
       "2       [Produced by Kanye West and Brian Miller]\\n\\n[...\n",
       "3       [Intro]\\nSo they ask me\\n\"Young boy\\nWhat you ...\n",
       "4       [Intro: Lil Wayne]\\nHaha\\nUh-huh\\nNo homo (You...\n",
       "                              ...                        \n",
       "1144    [Hook]\\nAnother night, slips away\\nIn other wo...\n",
       "1145    [Intro: Michael Jackson and 60 Minutes' Ed Bra...\n",
       "1146    [Chorus: Kid Cudi & John Legend]\\nI got the wo...\n",
       "1147    [Chorus 1: Bruno Mars & B.o.B]\\nBeautiful girl...\n",
       "1148    [Intro]\\nK-K-K-K-K-K-Mac\\n\\n[Verse 1: Chris Br...\n",
       "Name: lyrics, Length: 1149, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls['lyrics']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0044976a-d87b-44a9-b5c4-bb5c259abe80",
   "metadata": {},
   "source": [
    "# Indexer\n",
    "\n",
    "The indexer creates an inverted index, mapping terms to their locations in documents for fast retrieval. \n",
    "- Needs preprocessed lyrics\n",
    "- Consists of two levels: a vocabulary of index terms (typically words) and lists that map each term to the documents where it appears.\n",
    "- Elasticsearch/Lucene builds inverted index\n",
    "- Metadata fields (genre, year, and song section) indexed separately.\n",
    "- Search engine incorporates a section-based filter: users to determine where their query terms appear in the lyrics (e.g., verse, chorus, bridge). - - These fields are structured using Elasticsearch mappings, allowing users to refine searches based on genre, release year, and specific song sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a91d832b-36b6-4fba-8a5b-5c7b9850ed95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apache Lucene or ElasticSearch\n",
    "# BM25 Inverted index\n",
    "# Query processor BM25. Prepare corpus fro BM25 (tokenized texts)\n",
    "\n",
    "def build_bm25_index(ls):\n",
    "    inverted_index = defaultdict(dict)\n",
    "    doc_lengths = {}\n",
    "    total_docs = len(ls)\n",
    "\n",
    "    for idx, row in ls.iterrows():\n",
    "        doc_id = row['id']\n",
    "        # Ensure tokens are separated properly\n",
    "        tokens = row['preprocessed_lyrics']\n",
    "        if isinstance(tokens, str):\n",
    "            tokens = tokens.split()\n",
    "\n",
    "        doc_lengths[doc_id] = len(tokens)\n",
    "\n",
    "        term_freqs = defaultdict(int)\n",
    "        for token in tokens:\n",
    "            term_freqs[token] += 1\n",
    "\n",
    "        for token, freq in term_freqs.items():\n",
    "            inverted_index[token][doc_id] = freq\n",
    "\n",
    "    return inverted_index, doc_lengths, total_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fb8f90a-eac9-4bb1-928d-019133597ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT Embedder\n",
    "bert_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "def build_bert_index(ls, model_name=\"sentence-transformers/all-MiniLM-L6-v2\"):\n",
    "    model = SentenceTransformer(model_name)\n",
    "    lyrics_texts = ls['preprocessed_lyrics'].astype(str).tolist()\n",
    "    embeddings = model.encode(lyrics_texts, convert_to_numpy=True)\n",
    "    doc_ids = ls[\"id\"].tolist()\n",
    "    doc_embeddings = dict(zip(doc_ids, embeddings))\n",
    "    return doc_embeddings, model  #  returns both index and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3223994-6835-4644-8d36-50d44fe8d0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_embeddings = np.load('bert_embeddings.npy',allow_pickle=False)\n",
    "\n",
    "# Get document IDs from your DataFrame\n",
    "doc_ids = ls[\"id\"].tolist()\n",
    "\n",
    "# Build a dictionary: {doc_id: embedding}\n",
    "bert_embeddings = dict(zip(doc_ids, bert_embeddings))\n",
    "# bert_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bf91c2-02eb-4fdb-a7a2-fa215ec27dbc",
   "metadata": {},
   "source": [
    "# Query processor\n",
    "- Tokenizing, stemming, and normalizing the query using NLTK or spaCy\n",
    "- Input: Query\n",
    "1. Fuzzy matching incorporated using Levenshtein distance to approximate string matching\n",
    "    - Datamuse API: Related words and phrases through Datamuse API\n",
    "2. Filtering with Elasticsearchâ€™s boolean queries (based on song metadata attributes, such as genre, release year, artist, and specific song sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c328cca3-7009-4ded-810a-fc83bc15dd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_stopwords = set(stopwords.words(\"english\"))\n",
    "lyrical_keep_words = {\n",
    "    # Pronouns\n",
    "    'i', 'you', 'me', 'we', 'my', 'your', 'she', 'her', 'his',\n",
    "    # Negations (full words + contractions)\n",
    "    'not', 'no', 'never',\n",
    "    \"don't\", \"can't\", \"won't\", \"didn't\", \"isn't\", \"aren't\",\n",
    "    # Emotional/vocal\n",
    "    'oh', 'hey', 'yeah'\n",
    "}\n",
    "\n",
    "custom_stopwords = base_stopwords - lyrical_keep_words\n",
    "stemmer = PorterStemmer()\n",
    "def bm25_query(query):\n",
    "    # Tokenize using the same regex: keep words, apostrophes, dashes, and brackets\n",
    "    words = re.findall(r\"[\\w'\\-\\[\\]]+\", query.lower())\n",
    "\n",
    "    # Keep if:\n",
    "    # - in lyrical keep words\n",
    "    # - contains an apostrophe (e.g., don't)\n",
    "    # - not in base stopwords\n",
    "    filtered = [\n",
    "        word for word in words\n",
    "        if (word in lyrical_keep_words) or (\"'\" in word) or (word not in base_stopwords)\n",
    "    ]\n",
    "\n",
    "    # Stem\n",
    "    stemmed = [stemmer.stem(word) for word in filtered]\n",
    "\n",
    "    return stemmed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c315d35-eb0c-4a6b-b2ca-b581b07f32e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT Scoring logic\n",
    "def encode_bert_query(query, model):\n",
    "    # Encode the raw query string\n",
    "    embedding = model.encode(query)\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b146c6d-e529-496e-ba8e-6208e8b80c43",
   "metadata": {},
   "source": [
    "# Baseline model: BM25 + BERT\n",
    "- Generates relevance scores for lyrics based on user's query\n",
    "\n",
    "- Ranking layer 1: BM25+BERT\n",
    "- Ranking layer 2: Datamuse API for phonetic alignment of lyrics with query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f618f15-c16d-4fb9-ac9d-6e015ac91dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ranking of lyrics with BM25\n",
    "\n",
    "# Load preprocessed lyrics\n",
    "tokenized_corpus = [str(doc).split() for doc in ls['preprocessed_lyrics']]\n",
    "bm25 = BM25Okapi(tokenized_corpus)\n",
    "\n",
    "def bm25_search(query, bm25_model, ls, top_k=5):\n",
    "    tokens = preprocess_bm25_query(query)\n",
    "    scores = bm25_model.get_scores(tokens)\n",
    "    top_indices = np.argsort(scores)[::-1][:top_k]\n",
    "    return ls.iloc[top_indices], scores \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d6d1409-13a0-44a5-9188-2bc46c4c7cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed query for BERT model to compare with document embeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "def bert_search(query, doc_embeddings, model, ls, top_k=5):\n",
    "    query_vec = encode_bert_query(query, model)\n",
    "\n",
    "    # Compute cosine similarity to each document\n",
    "    doc_ids = list(doc_embeddings.keys())\n",
    "    doc_vecs = np.array([doc_embeddings[doc_id] for doc_id in doc_ids])\n",
    "    \n",
    "    similarities = cosine_similarity([query_vec], doc_vecs)[0]\n",
    "    top_indices = np.argsort(similarities)[::-1][:top_k]\n",
    "\n",
    "    top_doc_ids = [doc_ids[i] for i in top_indices]\n",
    "    return ls[ls['id'].isin(top_doc_ids)][['title', 'artist', 'lyrics']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ece673a-e3c9-46df-aa6f-eb8f61aa727a",
   "metadata": {},
   "source": [
    "# Enter query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47ca914d-bebd-45ad-8dfa-53d4ae06620b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BM25 Results:\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'preprocess_bm25_query' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYoung boy\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBM25 Results:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mbm25_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mls\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mBERT Results:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(bert_search(query, bert_embeddings, bert_model, ls))\n",
      "Cell \u001b[0;32mIn[14], line 8\u001b[0m, in \u001b[0;36mbm25_search\u001b[0;34m(query, bm25_model, ls, top_k)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbm25_search\u001b[39m(query, bm25_model, ls, top_k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m----> 8\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_bm25_query\u001b[49m(query)\n\u001b[1;32m      9\u001b[0m     scores \u001b[38;5;241m=\u001b[39m bm25_model\u001b[38;5;241m.\u001b[39mget_scores(tokens)\n\u001b[1;32m     10\u001b[0m     top_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(scores)[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][:top_k]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'preprocess_bm25_query' is not defined"
     ]
    }
   ],
   "source": [
    "# Step 1: Build BM25 model using preprocessed_lyrics\n",
    "tokenized_corpus = [str(doc).split() for doc in ls['preprocessed_lyrics']]\n",
    "bm25_model = BM25Okapi(tokenized_corpus)\n",
    "\n",
    "# # Step 2: Build BERT index\n",
    "# bert_index, bert_model = build_bert_index(ls, model_name)\n",
    "\n",
    "# Step 3: Example Query\n",
    "query = \"Young boy\"\n",
    "\n",
    "print(\"BM25 Results:\\n\")\n",
    "print(bm25_search(query, 5, ls))\n",
    "\n",
    "print(\"\\nBERT Results:\\n\")\n",
    "print(bert_search(query, bert_embeddings, bert_model, ls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "787b8f5c-3db8-4472-b589-d50f622ffb3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>genre</th>\n",
       "      <th>artist</th>\n",
       "      <th>year</th>\n",
       "      <th>views</th>\n",
       "      <th>features</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>id</th>\n",
       "      <th>preprocessed_lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Killa Cam</td>\n",
       "      <td>rap</td>\n",
       "      <td>Cam'ron</td>\n",
       "      <td>2004</td>\n",
       "      <td>173166</td>\n",
       "      <td>{\"Cam\\\\'ron\",\"Opera Steve\"}</td>\n",
       "      <td>[Chorus: Opera Steve &amp; Cam'ron]\\nKilla Cam, Ki...</td>\n",
       "      <td>1</td>\n",
       "      <td>[choru opera steve cam'ron] killa cam killa ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Can I Live</td>\n",
       "      <td>rap</td>\n",
       "      <td>JAY-Z</td>\n",
       "      <td>1996</td>\n",
       "      <td>468624</td>\n",
       "      <td>{}</td>\n",
       "      <td>[Produced by Irv Gotti]\\n\\n[Intro]\\nYeah, hah,...</td>\n",
       "      <td>3</td>\n",
       "      <td>[produc irv gotti] [intro] yeah hah yeah roc-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Down and Out</td>\n",
       "      <td>rap</td>\n",
       "      <td>Cam'ron</td>\n",
       "      <td>2004</td>\n",
       "      <td>144404</td>\n",
       "      <td>{\"Cam\\\\'ron\",\"Kanye West\",\"Syleena Johnson\"}</td>\n",
       "      <td>[Produced by Kanye West and Brian Miller]\\n\\n[...</td>\n",
       "      <td>5</td>\n",
       "      <td>[produc kany west brian miller] [intro cam'ron...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fly In</td>\n",
       "      <td>rap</td>\n",
       "      <td>Lil Wayne</td>\n",
       "      <td>2005</td>\n",
       "      <td>78271</td>\n",
       "      <td>{}</td>\n",
       "      <td>[Intro]\\nSo they ask me\\n\"Young boy\\nWhat you ...</td>\n",
       "      <td>6</td>\n",
       "      <td>[intro] ask me young boy you gon' second time ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lollipop Remix</td>\n",
       "      <td>rap</td>\n",
       "      <td>Lil Wayne</td>\n",
       "      <td>2008</td>\n",
       "      <td>580832</td>\n",
       "      <td>{\"Kanye West\",\"Static Major\"}</td>\n",
       "      <td>[Intro: Lil Wayne]\\nHaha\\nUh-huh\\nNo homo (You...</td>\n",
       "      <td>7</td>\n",
       "      <td>[intro lil wayne] haha uh-huh no homo young mu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            title genre     artist  year   views  \\\n",
       "0       Killa Cam   rap    Cam'ron  2004  173166   \n",
       "1      Can I Live   rap      JAY-Z  1996  468624   \n",
       "2    Down and Out   rap    Cam'ron  2004  144404   \n",
       "3          Fly In   rap  Lil Wayne  2005   78271   \n",
       "4  Lollipop Remix   rap  Lil Wayne  2008  580832   \n",
       "\n",
       "                                       features  \\\n",
       "0                   {\"Cam\\\\'ron\",\"Opera Steve\"}   \n",
       "1                                            {}   \n",
       "2  {\"Cam\\\\'ron\",\"Kanye West\",\"Syleena Johnson\"}   \n",
       "3                                            {}   \n",
       "4                 {\"Kanye West\",\"Static Major\"}   \n",
       "\n",
       "                                              lyrics  id  \\\n",
       "0  [Chorus: Opera Steve & Cam'ron]\\nKilla Cam, Ki...   1   \n",
       "1  [Produced by Irv Gotti]\\n\\n[Intro]\\nYeah, hah,...   3   \n",
       "2  [Produced by Kanye West and Brian Miller]\\n\\n[...   5   \n",
       "3  [Intro]\\nSo they ask me\\n\"Young boy\\nWhat you ...   6   \n",
       "4  [Intro: Lil Wayne]\\nHaha\\nUh-huh\\nNo homo (You...   7   \n",
       "\n",
       "                                 preprocessed_lyrics  \n",
       "0  [choru opera steve cam'ron] killa cam killa ca...  \n",
       "1  [produc irv gotti] [intro] yeah hah yeah roc-a...  \n",
       "2  [produc kany west brian miller] [intro cam'ron...  \n",
       "3  [intro] ask me young boy you gon' second time ...  \n",
       "4  [intro lil wayne] haha uh-huh no homo young mu...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "d80f4507-c130-4344-ae56-73e09f9e79a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hybrid search\n",
    "bert_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "def hybrid_search(query, ls, bm25_model, bert_model, bert_embeddings, top_k_bm25=20, top_k_final=5, weight=0.5, \n",
    "                  genre=None, artist=None, release_year=None, title=None):\n",
    "    # Apply metadata filters\n",
    "    filtered_ls = ls.copy()\n",
    "    if title:\n",
    "        \n",
    "    if genre:\n",
    "        filtered_ls = filtered_ls[filtered_ls['genre'].str.lower() == genre.lower()]\n",
    "    if artist:\n",
    "        filtered_ls = filtered_ls[filtered_ls['artist'].str.lower() == artist.lower()]\n",
    "    if release_year:\n",
    "        filtered_ls = filtered_ls[filtered_ls['year'] == release_year]\n",
    "\n",
    "    if filtered_ls.empty:\n",
    "        print(\"No matching documents found after applying filters.\")\n",
    "        return pd.DataFrame()  # Safe exit\n",
    "\n",
    "    # Build BM25 model on filtered data\n",
    "    filtered_lyrics_tokens = [bm25_query(lyrics) for lyrics in filtered_ls['preprocessed_lyrics']]\n",
    "    bm25_model = BM25Okapi(filtered_lyrics_tokens)\n",
    "\n",
    "    # Get BM25 scores and top results\n",
    "    bm25_results, bm25_scores = bm25_search(query, bm25_model=bm25_model, ls=filtered_ls, top_k=top_k_bm25)\n",
    "    bm25_top_ids = bm25_results['id'].tolist()\n",
    "\n",
    "    # BERT query embedding\n",
    "    query_embedding = encode_bert_query(query, bert_model)\n",
    "\n",
    "    # Score using BERT similarity\n",
    "    bert_scores = []\n",
    "    bm25_selected_scores = []\n",
    "    for doc_id in bm25_top_ids:\n",
    "        doc_embedding = bert_embeddings[doc_id]\n",
    "        sim = cosine_similarity([query_embedding], [doc_embedding])[0][0]\n",
    "        bert_scores.append(sim)\n",
    "\n",
    "        # Get BM25 score using filtered_ls index\n",
    "        index_in_filtered = filtered_ls[filtered_ls['id'] == doc_id].index[0]\n",
    "        bm25_selected_scores.append(bm25_scores[filtered_ls.index.get_loc(index_in_filtered)])\n",
    "\n",
    "    # Normalize scores\n",
    "    bert_scores = np.array(bert_scores)\n",
    "    bm25_selected_scores = np.array(bm25_selected_scores)\n",
    "\n",
    "    bert_norm = (bert_scores - bert_scores.min()) / (bert_scores.max() - bert_scores.min() + 1e-8)\n",
    "    bm25_norm = (bm25_selected_scores - bm25_selected_scores.min()) / (bm25_selected_scores.max() - bm25_selected_scores.min() + 1e-8)\n",
    "\n",
    "    # Combine scores\n",
    "    combined_scores = weight * bert_norm + (1 - weight) * bm25_norm\n",
    "    sorted_indices = np.argsort(combined_scores)[::-1][:top_k_final]\n",
    "    final_ids = [bm25_top_ids[i] for i in sorted_indices]\n",
    "\n",
    "    # Build the result DataFrame\n",
    "    results_df = ls[ls['id'].isin(final_ids)][['id', 'title', 'artist', 'lyrics']].copy()\n",
    "    results_df['bm25_score'] = [bm25_selected_scores[i] for i in sorted_indices]\n",
    "    results_df['bert_score'] = [bert_scores[i] for i in sorted_indices]\n",
    "    results_df['combined_score'] = [combined_scores[i] for i in sorted_indices]\n",
    "\n",
    "    return results_df.sort_values(by='combined_score', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a22b4780-8665-48a2-9dd8-1d2cfdd4cd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same function with title filter incorporated and no errors?\n",
    "def hybrid_search(query, ls, bm25_model, bert_model, bert_embeddings, top_k_bm25=20, top_k_final=5, weight=0.5, \n",
    "                  genre=None, artist=None, release_year=None, search_title_first=False):\n",
    "    \n",
    "    # Apply metadata filters\n",
    "    filtered_ls = ls.copy()\n",
    "    if genre:\n",
    "        filtered_ls = filtered_ls[filtered_ls['genre'].str.lower() == genre.lower()]\n",
    "    if artist:\n",
    "        filtered_ls = filtered_ls[filtered_ls['artist'].str.lower() == artist.lower()]\n",
    "    if release_year:\n",
    "        filtered_ls = filtered_ls[filtered_ls['year'] == release_year]\n",
    "\n",
    "    if filtered_ls.empty:\n",
    "        print(\"No matching documents found after applying filters.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # First try title search\n",
    "    if search_title_first:\n",
    "        tokenized_titles = [bm25_query(title) for title in filtered_ls['title']]\n",
    "        title_bm25 = BM25Okapi(tokenized_titles)\n",
    "        query_tokens = bm25_query(query)\n",
    "        title_scores = title_bm25.get_scores(query_tokens)\n",
    "        \n",
    "        top_title_indices = np.argsort(title_scores)[::-1][:top_k_final]\n",
    "        top_title_scores = [title_scores[i] for i in top_title_indices]\n",
    "        top_title_matches = filtered_ls.iloc[top_title_indices].copy()\n",
    "        top_title_matches['bm25_score'] = top_title_scores\n",
    "        \n",
    "        # Optional: threshold to fall back to full search\n",
    "        if top_title_matches['bm25_score'].max() > 1.0:  # Adjust threshold as needed\n",
    "            return top_title_matches[['id', 'title', 'artist', 'lyrics']].reset_index(drop=True)\n",
    "\n",
    "    # Proceed with full hybrid search (lyrics)\n",
    "    tokenized_lyrics = [bm25_query(lyrics) for lyrics in filtered_ls['preprocessed_lyrics']]\n",
    "    bm25_model = BM25Okapi(tokenized_lyrics)\n",
    "    \n",
    "    bm25_results, bm25_scores = bm25_search(query, bm25_model=bm25_model, ls=filtered_ls, top_k=top_k_bm25)\n",
    "    bm25_top_ids = bm25_results['id'].tolist()\n",
    "\n",
    "    # BERT query embedding\n",
    "    query_embedding = encode_bert_query(query, bert_model)\n",
    "\n",
    "    # BERT scores\n",
    "    bert_scores = []\n",
    "    bm25_selected_scores = []\n",
    "    for doc_id in bm25_top_ids:\n",
    "        doc_embedding = bert_embeddings[doc_id]\n",
    "        sim = cosine_similarity([query_embedding], [doc_embedding])[0][0]\n",
    "        bert_scores.append(sim)\n",
    "\n",
    "        index_in_filtered = filtered_ls[filtered_ls['id'] == doc_id].index[0]\n",
    "        bm25_selected_scores.append(bm25_scores[filtered_ls.index.get_loc(index_in_filtered)])\n",
    "\n",
    "    # Normalize\n",
    "    bert_scores = np.array(bert_scores)\n",
    "    bm25_selected_scores = np.array(bm25_selected_scores)\n",
    "\n",
    "    bert_norm = (bert_scores - bert_scores.min()) / (bert_scores.max() - bert_scores.min() + 1e-8)\n",
    "    bm25_norm = (bm25_selected_scores - bm25_selected_scores.min()) / (bm25_selected_scores.max() - bm25_selected_scores.min() + 1e-8)\n",
    "    combined_scores = weight * bert_norm + (1 - weight) * bm25_norm\n",
    "\n",
    "    # Final sort\n",
    "    sorted_indices = np.argsort(combined_scores)[::-1][:top_k_final]\n",
    "    final_ids = [bm25_top_ids[i] for i in sorted_indices]\n",
    "\n",
    "    results_df = ls[ls['id'].isin(final_ids)][['id', 'title', 'artist', 'lyrics']].copy()\n",
    "    results_df['bm25_score'] = [bm25_selected_scores[i] for i in sorted_indices]\n",
    "    results_df['bert_score'] = [bert_scores[i] for i in sorted_indices]\n",
    "    results_df['combined_score'] = [combined_scores[i] for i in sorted_indices]\n",
    "\n",
    "    return results_df.sort_values(by='combined_score', ascending=False).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cdf133a2-0567-4ff1-9561-7e393cb5f4a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id        title             artist  \\\n",
      "0   1189    Alejandro          Lady Gaga   \n",
      "1   1313  Bad Romance          Lady Gaga   \n",
      "2  21575   Pirate Jet           Gorillaz   \n",
      "3   1299    Paper Bag        Fiona Apple   \n",
      "4   1282     My Girls  Animal Collective   \n",
      "\n",
      "                                              lyrics  \n",
      "0  [Intro]\\nI know that we are young, and I know ...  \n",
      "1  [Intro]\\nOh-oh-oh-oh-oh, oh-oh-oh-oh, oh-oh-oh...  \n",
      "2  [Verse: 2-D & The Purple, the People, the Plas...  \n",
      "3  [Verse 1]\\nI was staring at the sky, just look...  \n",
      "4  [Intro]\\nIsn't much that I feel I need\\nA soli...  \n"
     ]
    }
   ],
   "source": [
    "# Implement hybrid search\n",
    "bm25_model = BM25Okapi([str(doc).split() for doc in ls['preprocessed_lyrics']])\n",
    "query = \"Alejandro\"\n",
    "results = hybrid_search(query, ls, bm25_model, bert_model, bert_embeddings, 20, 5, weight=0.5, genre= 'pop', search_title_first=True)\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ab3e2a-b7f5-4383-975b-47cdacbdf429",
   "metadata": {},
   "source": [
    "# Augmented model: BM25 + Datamuse API + BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "44f46773-31df-47f1-a97f-6e7b89ae0510",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "def get_related_words(query, max_results=10):\n",
    "    url = \"https://api.datamuse.com/words\"\n",
    "    params = {\n",
    "        \"ml\": query,      # 'ml' = means like (semantic similarity)\n",
    "        \"max\": max_results\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        words = [item['word'] for item in response.json()]\n",
    "        return words\n",
    "    else:\n",
    "        print(\"Datamuse API error:\", response.status_code)\n",
    "        return []\n",
    "\n",
    "\n",
    "# Expand the query by adding related terms from Datamuse\n",
    "def expand_query_with_related_terms(query, max_related=5):\n",
    "    related = get_related_words(query, max_related)\n",
    "    expanded = query + \" \" + \" \".join(related)\n",
    "    return expanded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "9ddfa7c5-2ef3-43e1-9bf8-c20ff7070acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Function to expand the query using the Datamuse API\n",
    "def expand_query_with_related_terms(query, max_related=5):\n",
    "    # Send request to Datamuse API to get related words and phrases\n",
    "    response = requests.get(f\"https://api.datamuse.com/words?ml={query}&max={max_related}\")\n",
    "    related_words = [word_info['word'] for word_info in response.json()]\n",
    "    \n",
    "    # Join related words with the original query for expansion\n",
    "    expanded_query = query + \" \" + \" \".join(related_words)\n",
    "    return expanded_query\n",
    "\n",
    "def hybrid_search(query, ls, bm25_model, bert_model, bert_embeddings, top_k_bm25=20, top_k_final=5, weight=0.5, \n",
    "                  genre=None, artist=None, release_year=None, search_title_first=False):\n",
    "    \n",
    "    # Apply metadata filters\n",
    "    filtered_ls = ls.copy()\n",
    "    if genre:\n",
    "        filtered_ls = filtered_ls[filtered_ls['genre'].str.lower() == genre.lower()]\n",
    "    if artist:\n",
    "        filtered_ls = filtered_ls[filtered_ls['artist'].str.lower() == artist.lower()]\n",
    "    if release_year:\n",
    "        filtered_ls = filtered_ls[filtered_ls['year'] == release_year]\n",
    "\n",
    "    if filtered_ls.empty:\n",
    "        print(\"No matching documents found after applying filters.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Expand query with related terms from Datamuse\n",
    "    expanded_query = expand_query_with_related_terms(query, max_related=5)\n",
    "    print(f\"Expanded Query: {expanded_query}\")  # Optional: print expanded query for debugging\n",
    "\n",
    "    # First try title search\n",
    "    if search_title_first:\n",
    "        tokenized_titles = [bm25_query(title) for title in filtered_ls['title']]\n",
    "        title_bm25 = BM25Okapi(tokenized_titles)\n",
    "        query_tokens = bm25_query(expanded_query)\n",
    "        title_scores = title_bm25.get_scores(query_tokens)\n",
    "        \n",
    "        top_title_indices = np.argsort(title_scores)[::-1][:top_k_final]\n",
    "        top_title_scores = [title_scores[i] for i in top_title_indices]\n",
    "        top_title_matches = filtered_ls.iloc[top_title_indices].copy()\n",
    "        top_title_matches['bm25_score'] = top_title_scores\n",
    "        \n",
    "        # Optional: threshold to fall back to full search\n",
    "        if top_title_matches['bm25_score'].max() > 1.0:  # Adjust threshold as needed\n",
    "            return top_title_matches[['id', 'title', 'artist', 'lyrics']].reset_index(drop=True)\n",
    "\n",
    "    # Proceed with full hybrid search (lyrics)\n",
    "    tokenized_lyrics = [bm25_query(lyrics) for lyrics in filtered_ls['preprocessed_lyrics']]\n",
    "    bm25_model = BM25Okapi(tokenized_lyrics)\n",
    "    \n",
    "    bm25_results, bm25_scores = bm25_search(expanded_query, bm25_model=bm25_model, ls=filtered_ls, top_k=top_k_bm25)\n",
    "    bm25_top_ids = bm25_results['id'].tolist()\n",
    "\n",
    "    # BERT query embedding\n",
    "    query_embedding = encode_bert_query(expanded_query, bert_model)\n",
    "\n",
    "    # BERT scores\n",
    "    bert_scores = []\n",
    "    bm25_selected_scores = []\n",
    "    for doc_id in bm25_top_ids:\n",
    "        doc_embedding = bert_embeddings[doc_id]\n",
    "        sim = cosine_similarity([query_embedding], [doc_embedding])[0][0]\n",
    "        bert_scores.append(sim)\n",
    "\n",
    "        index_in_filtered = filtered_ls[filtered_ls['id'] == doc_id].index[0]\n",
    "        bm25_selected_scores.append(bm25_scores[filtered_ls.index.get_loc(index_in_filtered)])\n",
    "\n",
    "    # Normalize\n",
    "    bert_scores = np.array(bert_scores)\n",
    "    bm25_selected_scores = np.array(bm25_selected_scores)\n",
    "\n",
    "    bert_norm = (bert_scores - bert_scores.min()) / (bert_scores.max() - bert_scores.min() + 1e-8)\n",
    "    bm25_norm = (bm25_selected_scores - bm25_selected_scores.min()) / (bm25_selected_scores.max() - bm25_selected_scores.min() + 1e-8)\n",
    "    combined_scores = weight * bert_norm + (1 - weight) * bm25_norm\n",
    "\n",
    "    # Final sort\n",
    "    sorted_indices = np.argsort(combined_scores)[::-1][:top_k_final]\n",
    "    final_ids = [bm25_top_ids[i] for i in sorted_indices]\n",
    "\n",
    "    results_df = ls[ls['id'].isin(final_ids)][['id', 'title', 'artist', 'lyrics']].copy()\n",
    "    results_df['bm25_score'] = [bm25_selected_scores[i] for i in sorted_indices]\n",
    "    results_df['bert_score'] = [bert_scores[i] for i in sorted_indices]\n",
    "    results_df['combined_score'] = [combined_scores[i] for i in sorted_indices]\n",
    "\n",
    "    return results_df.sort_values(by='combined_score', ascending=False).reset_index(drop=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "700a13c6-d058-4879-8219-fb8e285555be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expanded Query: don't call my name names naming term give title\n",
      "     id               title           artist  \\\n",
      "0   741             Anxiety  Black Eyed Peas   \n",
      "1   911           Ego Remix           Beyonc   \n",
      "2   916         Billionaire     Travie McCoy   \n",
      "3  1170  Runaway Love Remix    Justin Bieber   \n",
      "4  1189           Alejandro        Lady Gaga   \n",
      "\n",
      "                                              lyrics  bm25_score  bert_score  \\\n",
      "0  [Verse 1]\\nI feel like I wanna smack somebody\\...    7.396500    0.318183   \n",
      "1  [Verse 1: Kanye West]\\nI got a big ego (Ha ha ...    6.256792    0.213124   \n",
      "2  [Pre-Chorus: Bruno Mars]\\nI wanna be a billion...    5.148655    0.141291   \n",
      "3  [Intro: Raekwon]\\nVisual visual, JB\\nYo, Ye, w...    2.757639    0.157454   \n",
      "4  [Intro]\\nI know that we are young, and I know ...    2.791590    0.147648   \n",
      "\n",
      "   combined_score  \n",
      "0        1.000000  \n",
      "1        0.738902  \n",
      "2        0.538147  \n",
      "3        0.404832  \n",
      "4        0.389947  \n"
     ]
    }
   ],
   "source": [
    "# Implement hybrid search\n",
    "bm25_model = BM25Okapi([str(doc).split() for doc in ls['preprocessed_lyrics']])\n",
    "query = \"don't call my name\"\n",
    "results = hybrid_search(query, ls, bm25_model, bert_model, bert_embeddings, 20, 5, weight=0.5, genre= 'pop', search_title_first=False)\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9294abc-0e11-473d-aa16-c721dbfb5390",
   "metadata": {},
   "source": [
    "# Analyze results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "45acd85b-5e79-4e61-8ada-c9bf6a1b7494",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Exact match precision and recall calculation\n",
    "def exact_match_precision_recall(retrieved_titles, relevant_titles, k=5):\n",
    "\n",
    "    retrieved_set = set(retrieved_titles[:k])  # Top k retrieved titles\n",
    "    relevant_set = set(relevant_titles)  # Ground truth titles\n",
    "    \n",
    "    # Precision\n",
    "    precision = len(retrieved_set & relevant_set) / k\n",
    "    # Recall\n",
    "    recall = len(retrieved_set & relevant_set) / len(relevant_titles) if relevant_titles else 0.0\n",
    "    \n",
    "    return precision, recall\n",
    "\n",
    "# F1-score \n",
    "def f1_at_k(precision, recall):\n",
    "    if precision + recall == 0:\n",
    "        return 0.0\n",
    "    return 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "# NDCG (by title relevance)\n",
    "def ndcg_at_k(retrieved_titles, relevant_titles, k=5):\n",
    "    \"\"\"\n",
    "    NDCG for title-based search.\n",
    "    \"\"\"\n",
    "    def dcg(scores):\n",
    "        return sum(score / np.log2(idx + 2) for idx, score in enumerate(scores))\n",
    "    \n",
    "    # Create binary relevance scores (1 if the title is in ground truth, else 0)\n",
    "    relevance_scores = [1 if title in relevant_titles else 0 for title in retrieved_titles[:k]]\n",
    "    ideal_relevance_scores = sorted(relevance_scores, reverse=True)\n",
    "    \n",
    "    dcg_val = dcg(relevance_scores)\n",
    "    idcg_val = dcg(ideal_relevance_scores)\n",
    "    \n",
    "    return dcg_val / idcg_val if idcg_val != 0 else 0.0\n",
    "\n",
    "# Example queries\n",
    "queries = [\"killer queen\", \"we will we will rock you\", \"she wears short skirts i wear\"]\n",
    "\n",
    "\n",
    "ground_truth_titles = {\n",
    "    \"killer queen\": [\"Killer Queen\", \"Alone in the Dark\", \"Solitude Anthem\"],\n",
    "    \"we will we will rock you\": [\"We Will Rock You\", \"Hot Summer Nights\", \"Sunshine Romance\"],\n",
    "    \"she wears short skirts i wear\": [\"You Belong With Me\", \"Broken Hearted\", \"Dreams Gone Bad\"]\n",
    "}\n",
    "\n",
    "for query in queries:\n",
    "    retrieved_titles = search_titles(query)  # Assume the search engine returns top 5 titles\n",
    "    relevant_titles = ground_truth_titles.get(query, [])  # The ground truth titles for this query\n",
    "\n",
    "    # Exact Match Evaluation\n",
    "    exact_precision, exact_recall = exact_match_precision_recall(retrieved_titles, relevant_titles, k=5)\n",
    "    \n",
    "    # F1-Score \n",
    "    exact_f1 = f1_at_k(exact_precision, exact_recall)\n",
    "    # NDCG score by title\n",
    "    ndcg = ndcg_at_k(retrieved_titles, relevant_titles, k=5)\n",
    "\n",
    "    print(f\"\\nQuery: '{query}'\")\n",
    "    print(f\"Exact Match Precision@5: {exact_precision:.2f}\")\n",
    "    print(f\"Exact Match Recall@5:    {exact_recall:.2f}\")\n",
    "    print(f\"Exact Match F1@5:        {exact_f1:.2f}\")\n",
    "    print(f\"NDCG@5 (Title):          {ndcg:.2f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ddc390b7-4ee5-4421-810a-aaf64d7a9166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>genre</th>\n",
       "      <th>artist</th>\n",
       "      <th>year</th>\n",
       "      <th>views</th>\n",
       "      <th>features</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>id</th>\n",
       "      <th>preprocessed_lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>Bohemian Rhapsody</td>\n",
       "      <td>rock</td>\n",
       "      <td>Queen</td>\n",
       "      <td>1975</td>\n",
       "      <td>9247817</td>\n",
       "      <td>{}</td>\n",
       "      <td>[Intro]\\nIs this the real life? Is this just f...</td>\n",
       "      <td>1063</td>\n",
       "      <td>[intro] real life fantasi caught landslid no e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 title genre artist  year    views features  \\\n",
       "571  Bohemian Rhapsody  rock  Queen  1975  9247817       {}   \n",
       "\n",
       "                                                lyrics    id  \\\n",
       "571  [Intro]\\nIs this the real life? Is this just f...  1063   \n",
       "\n",
       "                                   preprocessed_lyrics  \n",
       "571  [intro] real life fantasi caught landslid no e...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls[ls['artist']=='Queen']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651c9fbc-121e-4115-af60-5c3bd6e3c9fc",
   "metadata": {},
   "source": [
    "# References\n",
    "https://medium.com/@bormotovk/hybrid-retrieval-combining-bert-and-bm25-for-enhanced-performance-4f6f80881c13\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
