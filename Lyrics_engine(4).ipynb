{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b26bf20f-3cb5-4d63-b4bf-680baba29b09",
   "metadata": {},
   "source": [
    "# Lyrics search engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2215e2e0-896d-4d77-87e6-745919d8aa59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rank_bm25 in /opt/conda/lib/python3.11/site-packages (0.2.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from rank_bm25) (2.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence_transformers in /opt/conda/lib/python3.11/site-packages (4.0.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /opt/conda/lib/python3.11/site-packages (from sentence_transformers) (4.51.2)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from sentence_transformers) (4.66.5)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.11/site-packages (from sentence_transformers) (2.6.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.11/site-packages (from sentence_transformers) (1.5.1)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.11/site-packages (from sentence_transformers) (1.14.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /opt/conda/lib/python3.11/site-packages (from sentence_transformers) (0.30.2)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.11/site-packages (from sentence_transformers) (10.4.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /opt/conda/lib/python3.11/site-packages (from sentence_transformers) (4.12.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2.32.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /opt/conda/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /opt/conda/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.5.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2024.8.30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.11/site-packages (3.9.1)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.11/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.11/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.11/site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from nltk) (4.66.5)\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "!pip install rank_bm25\n",
    "!pip install sentence_transformers\n",
    "!pip install nltk\n",
    "import rank_bm25\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import json\n",
    "from rank_bm25 import BM25Okapi\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from rank_bm25 import BM25Okapi\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3379af4f-644b-40e0-a8d1-c2350f04319b",
   "metadata": {},
   "source": [
    "# Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c0f69c83-8a70-4066-9ae8-f03fc613407b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>tag</th>\n",
       "      <th>artist</th>\n",
       "      <th>year</th>\n",
       "      <th>views</th>\n",
       "      <th>features</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>id</th>\n",
       "      <th>preprocessed_lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Killa Cam</td>\n",
       "      <td>rap</td>\n",
       "      <td>Cam'ron</td>\n",
       "      <td>2004</td>\n",
       "      <td>173166</td>\n",
       "      <td>{\"Cam\\\\'ron\",\"Opera Steve\"}</td>\n",
       "      <td>[Chorus: Opera Steve &amp; Cam'ron]\\nKilla Cam, Ki...</td>\n",
       "      <td>1</td>\n",
       "      <td>[choru opera steve cam'ron] killa cam killa ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Can I Live</td>\n",
       "      <td>rap</td>\n",
       "      <td>JAY-Z</td>\n",
       "      <td>1996</td>\n",
       "      <td>468624</td>\n",
       "      <td>{}</td>\n",
       "      <td>[Produced by Irv Gotti]\\n\\n[Intro]\\nYeah, hah,...</td>\n",
       "      <td>3</td>\n",
       "      <td>[produc irv gotti] [intro] yeah hah yeah roc-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Down and Out</td>\n",
       "      <td>rap</td>\n",
       "      <td>Cam'ron</td>\n",
       "      <td>2004</td>\n",
       "      <td>144404</td>\n",
       "      <td>{\"Cam\\\\'ron\",\"Kanye West\",\"Syleena Johnson\"}</td>\n",
       "      <td>[Produced by Kanye West and Brian Miller]\\n\\n[...</td>\n",
       "      <td>5</td>\n",
       "      <td>[produc kany west brian miller] [intro cam'ron...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fly In</td>\n",
       "      <td>rap</td>\n",
       "      <td>Lil Wayne</td>\n",
       "      <td>2005</td>\n",
       "      <td>78271</td>\n",
       "      <td>{}</td>\n",
       "      <td>[Intro]\\nSo they ask me\\n\"Young boy\\nWhat you ...</td>\n",
       "      <td>6</td>\n",
       "      <td>[intro] ask me young boy you gon' second time ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lollipop Remix</td>\n",
       "      <td>rap</td>\n",
       "      <td>Lil Wayne</td>\n",
       "      <td>2008</td>\n",
       "      <td>580832</td>\n",
       "      <td>{\"Kanye West\",\"Static Major\"}</td>\n",
       "      <td>[Intro: Lil Wayne]\\nHaha\\nUh-huh\\nNo homo (You...</td>\n",
       "      <td>7</td>\n",
       "      <td>[intro lil wayne] haha uh-huh no homo young mu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            title  tag     artist  year   views  \\\n",
       "0       Killa Cam  rap    Cam'ron  2004  173166   \n",
       "1      Can I Live  rap      JAY-Z  1996  468624   \n",
       "2    Down and Out  rap    Cam'ron  2004  144404   \n",
       "3          Fly In  rap  Lil Wayne  2005   78271   \n",
       "4  Lollipop Remix  rap  Lil Wayne  2008  580832   \n",
       "\n",
       "                                       features  \\\n",
       "0                   {\"Cam\\\\'ron\",\"Opera Steve\"}   \n",
       "1                                            {}   \n",
       "2  {\"Cam\\\\'ron\",\"Kanye West\",\"Syleena Johnson\"}   \n",
       "3                                            {}   \n",
       "4                 {\"Kanye West\",\"Static Major\"}   \n",
       "\n",
       "                                              lyrics  id  \\\n",
       "0  [Chorus: Opera Steve & Cam'ron]\\nKilla Cam, Ki...   1   \n",
       "1  [Produced by Irv Gotti]\\n\\n[Intro]\\nYeah, hah,...   3   \n",
       "2  [Produced by Kanye West and Brian Miller]\\n\\n[...   5   \n",
       "3  [Intro]\\nSo they ask me\\n\"Young boy\\nWhat you ...   6   \n",
       "4  [Intro: Lil Wayne]\\nHaha\\nUh-huh\\nNo homo (You...   7   \n",
       "\n",
       "                                 preprocessed_lyrics  \n",
       "0  [choru opera steve cam'ron] killa cam killa ca...  \n",
       "1  [produc irv gotti] [intro] yeah hah yeah roc-a...  \n",
       "2  [produc kany west brian miller] [intro cam'ron...  \n",
       "3  [intro] ask me young boy you gon' second time ...  \n",
       "4  [intro lil wayne] haha uh-huh no homo young mu...  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls= pd.read_csv('preprocessed_genius_lyrics.csv')\n",
    "ls.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "ls.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b242c497-8cd0-4016-b4aa-e3744532a314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [Chorus: Opera Steve & Cam'ron]\\nKilla Cam, Ki...\n",
       "1       [Produced by Irv Gotti]\\n\\n[Intro]\\nYeah, hah,...\n",
       "2       [Produced by Kanye West and Brian Miller]\\n\\n[...\n",
       "3       [Intro]\\nSo they ask me\\n\"Young boy\\nWhat you ...\n",
       "4       [Intro: Lil Wayne]\\nHaha\\nUh-huh\\nNo homo (You...\n",
       "                              ...                        \n",
       "1144    [Hook]\\nAnother night, slips away\\nIn other wo...\n",
       "1145    [Intro: Michael Jackson and 60 Minutes' Ed Bra...\n",
       "1146    [Chorus: Kid Cudi & John Legend]\\nI got the wo...\n",
       "1147    [Chorus 1: Bruno Mars & B.o.B]\\nBeautiful girl...\n",
       "1148    [Intro]\\nK-K-K-K-K-K-Mac\\n\\n[Verse 1: Chris Br...\n",
       "Name: lyrics, Length: 1149, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls['lyrics']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0044976a-d87b-44a9-b5c4-bb5c259abe80",
   "metadata": {},
   "source": [
    "# Indexer\n",
    "\n",
    "The indexer creates an inverted index, mapping terms to their locations in documents for fast retrieval. \n",
    "- Needs preprocessed lyrics\n",
    "- Consists of two levels: a vocabulary of index terms (typically words) and lists that map each term to the documents where it appears.\n",
    "- Elasticsearch/Lucene builds inverted index\n",
    "- Metadata fields (genre, year, and song section) indexed separately.\n",
    "- Search engine incorporates a section-based filter: users to determine where their query terms appear in the lyrics (e.g., verse, chorus, bridge). - - These fields are structured using Elasticsearch mappings, allowing users to refine searches based on genre, release year, and specific song sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a91d832b-36b6-4fba-8a5b-5c7b9850ed95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apache Lucene or ElasticSearch\n",
    "# BM25 Inverted index\n",
    "# Query processor BM25. Prepare corpus fro BM25 (tokenized texts)\n",
    "\n",
    "def build_bm25_index(ls):\n",
    "    inverted_index = defaultdict(dict)\n",
    "    doc_lengths = {}\n",
    "    total_docs = len(ls)\n",
    "\n",
    "    for idx, row in ls.iterrows():\n",
    "        doc_id = row['id']\n",
    "        # Ensure tokens are separated properly\n",
    "        tokens = row['preprocessed_lyrics']\n",
    "        if isinstance(tokens, str):\n",
    "            tokens = tokens.split()\n",
    "\n",
    "        doc_lengths[doc_id] = len(tokens)\n",
    "\n",
    "        term_freqs = defaultdict(int)\n",
    "        for token in tokens:\n",
    "            term_freqs[token] += 1\n",
    "\n",
    "        for token, freq in term_freqs.items():\n",
    "            inverted_index[token][doc_id] = freq\n",
    "\n",
    "    return inverted_index, doc_lengths, total_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3fb8f90a-eac9-4bb1-928d-019133597ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT Embedder\n",
    "bert_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "def build_bert_index(ls, model_name=\"sentence-transformers/all-MiniLM-L6-v2\"):\n",
    "    model = SentenceTransformer(model_name)\n",
    "    lyrics_texts = ls['preprocessed_lyrics'].astype(str).tolist()\n",
    "    embeddings = model.encode(lyrics_texts, convert_to_numpy=True)\n",
    "    doc_ids = ls[\"id\"].tolist()\n",
    "    doc_embeddings = dict(zip(doc_ids, embeddings))\n",
    "    return doc_embeddings, model  #  returns both index and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f3223994-6835-4644-8d36-50d44fe8d0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_embeddings = np.load('bert_embeddings.npy',allow_pickle=False)\n",
    "\n",
    "# Get document IDs from your DataFrame\n",
    "doc_ids = ls[\"id\"].tolist()\n",
    "\n",
    "# Build a dictionary: {doc_id: embedding}\n",
    "bert_embeddings = dict(zip(doc_ids, bert_embeddings))\n",
    "# bert_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bf91c2-02eb-4fdb-a7a2-fa215ec27dbc",
   "metadata": {},
   "source": [
    "# Query processor\n",
    "- Tokenizing, stemming, and normalizing the query using NLTK or spaCy\n",
    "- Input: Query\n",
    "1. Fuzzy matching incorporated using Levenshtein distance to approximate string matching\n",
    "    - Datamuse API: Related words and phrases through Datamuse API\n",
    "2. Filtering with Elasticsearch’s boolean queries (based on song metadata attributes, such as genre, release year, artist, and specific song sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c328cca3-7009-4ded-810a-fc83bc15dd4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#BM25 Scoring logic\n",
    "# My function, but I think James's is better\n",
    "# def preprocess_bm25_query(query):\n",
    "#     # Lowercase, remove non-alphanumeric chars, split\n",
    "#     query = query.lower()\n",
    "#     tokens = re.findall(r'\\b\\w+\\b', query)  # Only words\n",
    "\n",
    "#     return tokens  # Return list of tokens\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "base_stopwords = set(stopwords.words(\"english\"))\n",
    "lyrical_keep_words = {\n",
    "    # Pronouns\n",
    "    'i', 'you', 'me', 'we', 'my', 'your', 'she', 'her', 'his',\n",
    "    # Negations (full words + contractions)\n",
    "    'not', 'no', 'never',\n",
    "    \"don't\", \"can't\", \"won't\", \"didn't\", \"isn't\", \"aren't\",\n",
    "    # Emotional/vocal\n",
    "    'oh', 'hey', 'yeah'\n",
    "}\n",
    "\n",
    "custom_stopwords = base_stopwords - lyrical_keep_words\n",
    "stemmer = PorterStemmer()\n",
    "def bm25_query(query):\n",
    "    # Tokenize using the same regex: keep words, apostrophes, dashes, and brackets\n",
    "    words = re.findall(r\"[\\w'\\-\\[\\]]+\", query.lower())\n",
    "\n",
    "    # Keep if:\n",
    "    # - in lyrical keep words\n",
    "    # - contains an apostrophe (e.g., don't)\n",
    "    # - not in base stopwords\n",
    "    filtered = [\n",
    "        word for word in words\n",
    "        if (word in lyrical_keep_words) or (\"'\" in word) or (word not in base_stopwords)\n",
    "    ]\n",
    "\n",
    "    # Stem\n",
    "    stemmed = [stemmer.stem(word) for word in filtered]\n",
    "\n",
    "    return stemmed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9c315d35-eb0c-4a6b-b2ca-b581b07f32e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT Scoring logic\n",
    "def encode_bert_query(query, model):\n",
    "    # Encode the raw query string\n",
    "    embedding = model.encode(query)\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b146c6d-e529-496e-ba8e-6208e8b80c43",
   "metadata": {},
   "source": [
    "# Baseline model: BM25 + BERT\n",
    "- Generates relevance scores for lyrics based on user's query\n",
    "\n",
    "- Ranking layer 1: BM25+BERT\n",
    "- Ranking layer 2: Datamuse API for phonetic alignment of lyrics with query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8f618f15-c16d-4fb9-ac9d-6e015ac91dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ranking of lyrics with BM25\n",
    "\n",
    "# Load preprocessed lyrics\n",
    "tokenized_corpus = [str(doc).split() for doc in ls['preprocessed_lyrics']]\n",
    "bm25 = BM25Okapi(tokenized_corpus)\n",
    "\n",
    "def bm25_search(query, top_k=5):\n",
    "    tokens = preprocess_bm25_query(query)\n",
    "    scores = bm25.get_scores(tokens)\n",
    "    top_indices = np.argsort(scores)[::-1][:top_k]\n",
    "    return ls.iloc[top_indices][['title', 'artist', 'lyrics']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2d6d1409-13a0-44a5-9188-2bc46c4c7cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed query for BERT model to compare with document embeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "def bert_search(query, doc_embeddings, model, ls, top_k=5):\n",
    "    query_vec = encode_bert_query(query, model)\n",
    "\n",
    "    # Compute cosine similarity to each document\n",
    "    doc_ids = list(doc_embeddings.keys())\n",
    "    doc_vecs = np.array([doc_embeddings[doc_id] for doc_id in doc_ids])\n",
    "    \n",
    "    similarities = cosine_similarity([query_vec], doc_vecs)[0]\n",
    "    top_indices = np.argsort(similarities)[::-1][:top_k]\n",
    "\n",
    "    top_doc_ids = [doc_ids[i] for i in top_indices]\n",
    "    return ls[ls['id'].isin(top_doc_ids)][['title', 'artist', 'lyrics']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ece673a-e3c9-46df-aa6f-eb8f61aa727a",
   "metadata": {},
   "source": [
    "# Enter query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "47ca914d-bebd-45ad-8dfa-53d4ae06620b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BM25 Results:\n",
      "\n",
      "                  title     artist  \\\n",
      "61             Go Crazy      Jeezy   \n",
      "134  This Is the Carter  Lil Wayne   \n",
      "847            Mr. 17.5      Jeezy   \n",
      "174         I Told Yall  Lil Wayne   \n",
      "320     Look Like Jesus      Lil B   \n",
      "\n",
      "                                                lyrics  \n",
      "61   [Produced by Don Cannon]\\n\\n[Verse 1: Young Je...  \n",
      "134  [Intro: Lil Wayne & Mannie Fresh]\\nOkay, um, f...  \n",
      "847  [Verse 1: Young Jeezy]\\nNew shoes on the Range...  \n",
      "174  [Intro: DJ K-Swift & Lil Wayne]\\nTold y'all, I...  \n",
      "320  [Intro]\\nNiggas hatin on me bro, but I don't g...  \n",
      "\n",
      "BERT Results:\n",
      "\n",
      "                          title     artist  \\\n",
      "3                        Fly In  Lil Wayne   \n",
      "12   What Happened to That Boy?    Birdman   \n",
      "413                My President      Jeezy   \n",
      "495                   Hype Boys       Sway   \n",
      "590               Young Forever      JAY-Z   \n",
      "\n",
      "                                                lyrics  \n",
      "3    [Intro]\\nSo they ask me\\n\"Young boy\\nWhat you ...  \n",
      "12   [Intro: Birdman]\\nAyy-ayy, ayy, ayy\\nYeah\\nTot...  \n",
      "413  [Intro: Young Jeezy]\\nYeah, be the realest shi...  \n",
      "495  [Verse 1]\\nHype boys, hype boys, everyone's a ...  \n",
      "590  [Intro: Mr. Hudson]\\nLet's dance in style, let...  \n"
     ]
    }
   ],
   "source": [
    "# Step 1: Build BM25 model using preprocessed_lyrics\n",
    "tokenized_corpus = [str(doc).split() for doc in ls['preprocessed_lyrics']]\n",
    "bm25_model = BM25Okapi(tokenized_corpus)\n",
    "\n",
    "# # Step 2: Build BERT index\n",
    "# bert_index, bert_model = build_bert_index(ls, model_name)\n",
    "\n",
    "# Step 3: Example Query\n",
    "query = \"Young boy\"\n",
    "\n",
    "print(\"BM25 Results:\\n\")\n",
    "print(bm25_search(query, 5))\n",
    "\n",
    "print(\"\\nBERT Results:\\n\")\n",
    "print(bert_search(query, bert_embeddings, bert_model, ls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d80f4507-c130-4344-ae56-73e09f9e79a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hybrid search\n",
    "bert_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "def hybrid_search(query, ls, bm25_model, bert_model, bert_embeddings, top_k_bm25=20, top_k_final=5, weight=0.5):\n",
    "\n",
    "    # Step 1: BM25 Search\n",
    "    bm25_tokens = query.lower().split()\n",
    "    bm25_scores = bm25_model.get_scores(bm25_tokens)\n",
    "    bm25_top_indices = np.argsort(bm25_scores)[::-1][:top_k_bm25]\n",
    "    bm25_top_ids = ls.iloc[bm25_top_indices]['id'].tolist()\n",
    "    \n",
    "    # Step 2: BERT query embedding\n",
    "    query_embedding = encode_bert_query(query, bert_model)\n",
    "    \n",
    "    # Step 3: BERT scores for BM25 top candidates\n",
    "    bert_scores = []\n",
    "    bm25_selected_scores = []\n",
    "    for doc_id in bm25_top_ids:\n",
    "        doc_embedding = bert_embeddings[doc_id]\n",
    "        sim = cosine_similarity([query_embedding], [doc_embedding])[0][0]\n",
    "        bert_scores.append(sim)\n",
    "        bm25_selected_scores.append(bm25_scores[ls[ls['id'] == doc_id].index[0]])\n",
    "\n",
    "    # Step 4: Normalize scores\n",
    "    bert_scores = np.array(bert_scores)\n",
    "    bm25_selected_scores = np.array(bm25_selected_scores)\n",
    "\n",
    "    bert_norm = (bert_scores - bert_scores.min()) / (bert_scores.max() - bert_scores.min() + 1e-8)\n",
    "    bm25_norm = (bm25_selected_scores - bm25_selected_scores.min()) / (bm25_selected_scores.max() - bm25_selected_scores.min() + 1e-8)\n",
    "\n",
    "    # Step 5: Combine and sort\n",
    "    combined_scores = weight * bert_norm + (1 - weight) * bm25_norm\n",
    "    sorted_indices = np.argsort(combined_scores)[::-1][:top_k_final]\n",
    "    final_ids = [bm25_top_ids[i] for i in sorted_indices]\n",
    "\n",
    "    return ls[ls['id'].isin(final_ids)][['id', 'title', 'artist', 'lyrics']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "cdf133a2-0567-4ff1-9561-7e393cb5f4a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id          title       artist  \\\n",
      "359    423         Bricks   Gucci Mane   \n",
      "361    427      Bird Call  J.R. Writer   \n",
      "379    477  Warrior Pt. 2  Lloyd Banks   \n",
      "385    450         B.O.B.      OutKast   \n",
      "1135  1395      Blasphemy         2Pac   \n",
      "\n",
      "                                                 lyrics  \n",
      "359   [Intro: Yo Gotti]\\nIt's your boy Yo Gotti, yea...  \n",
      "361   [Hook: J.R. Writer]\\nTo all my hustlers, rock ...  \n",
      "379   [Intro: Eminem]\\nWoo!!! Yeah!!! Remix!!! (50 C...  \n",
      "385   [Intro: André 3000]\\nOne, two\\nOne, two, three...  \n",
      "1135  [Intro: This Week In Bible Prophecy]\\nGod has ...  \n"
     ]
    }
   ],
   "source": [
    "# Implement hybrid search\n",
    "bm25_model = BM25Okapi([str(doc).split() for doc in ls['preprocessed_lyrics']])\n",
    "query = \"jerusalem bells\"\n",
    "results = hybrid_search(query, ls, bm25_model, bert_model, bert_embeddings, 20, 5, weight=0.2)\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9294abc-0e11-473d-aa16-c721dbfb5390",
   "metadata": {},
   "source": [
    "# Analyze results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "45acd85b-5e79-4e61-8ada-c9bf6a1b7494",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'comparison'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'comparison'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 20\u001b[0m\n\u001b[1;32m     16\u001b[0m     analysis_df \u001b[38;5;241m=\u001b[39m analysis_df\u001b[38;5;241m.\u001b[39mloc[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImproved\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnchanged\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWorsened\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m analysis_df\n\u001b[0;32m---> 20\u001b[0m \u001b[43manalyze_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[53], line 3\u001b[0m, in \u001b[0;36manalyze_results\u001b[0;34m(results_df)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21manalyze_results\u001b[39m(results_df):\n\u001b[0;32m----> 3\u001b[0m     comparison_counts \u001b[38;5;241m=\u001b[39m \u001b[43mresults_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcomparison\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mvalue_counts()\n\u001b[1;32m      5\u001b[0m     total_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(results_df)\n\u001b[1;32m      7\u001b[0m     analysis_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCount\u001b[39m\u001b[38;5;124m\"\u001b[39m: comparison_counts,\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPercentage\u001b[39m\u001b[38;5;124m\"\u001b[39m: (comparison_counts \u001b[38;5;241m/\u001b[39m total_results) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m     10\u001b[0m     })\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'comparison'"
     ]
    }
   ],
   "source": [
    "#Analyze results\n",
    "def analyze_results(results_df):\n",
    "    comparison_counts = results_df['comparison'].value_counts()\n",
    "\n",
    "    total_results = len(results_df)\n",
    "\n",
    "    analysis_df = pd.DataFrame({\n",
    "        \"Count\": comparison_counts,\n",
    "        \"Percentage\": (comparison_counts / total_results) * 100\n",
    "    })\n",
    "\n",
    "    for status in ['Improved', 'Unchanged', 'Worsened']:\n",
    "        if status not in analysis_df.index:\n",
    "            analysis_df.loc[status] = [0, 0.0]  # Add missing status with 0 count and 0% percentage\n",
    "\n",
    "    analysis_df = analysis_df.loc[['Improved', 'Unchanged', 'Worsened']]\n",
    "\n",
    "    return analysis_df\n",
    "\n",
    "analyze_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e2b10a-5c2f-49a3-9de3-509974fa2256",
   "metadata": {},
   "source": [
    "# Augmented model: BM25 + Datamuse API + BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651c9fbc-121e-4115-af60-5c3bd6e3c9fc",
   "metadata": {},
   "source": [
    "# References\n",
    "https://medium.com/@bormotovk/hybrid-retrieval-combining-bert-and-bm25-for-enhanced-performance-4f6f80881c13\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
